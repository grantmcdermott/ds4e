[{"path":"index.html","id":"welcome","chapter":"Welcome","heading":"Welcome","text":"website Data Science Economists Animals. \nbook much early development stages, draws lecture\nmaterial refining last several years. ’re \nactively looking feedback yet, hope ’ve managed build \nenough chapters basic book structure.’re interested motivation book, placeholder text Grant’s syllabus:seminar (ED: book) targeted economics PhD students (ED: animals) introduce modern data science toolkit. material likely overlap quantitative empirical methods courses, just another econometrics course. Rather, goal bring speed practical tools techniques feel benefit dissertation work future research career. includes many seemingly forgotten skills — like find interesting data sets “wild” actually clean — crucial successful scientific project, typically excluded core econometrics statistics classes. cover topics like version control effective project management; programming; data acquisition (e.g. web-scraping), cleaning visualization; GIS remote sensing products; tools big data analysis (e.g. relational databases, cloud computation machine learning). short, cover things wish someone taught starting graduate school.use renv snapshot project environment. can install \npackages needed run code book :Note might need extra packages want build book locally (unlikely):","code":"\n# renv::init() ## Only run this line if the next line returns an error\nrenv::restore(prompt = FALSE)\nlibrary(bslib)\nlibrary(downlit)\nlibrary(usethis)"},{"path":"intro.html","id":"intro","chapter":"1 Introduction","heading":"1 Introduction","text":"can label chapter section titles using {#label} , e.g., can reference Chapter 1.can write citations, . example, using bookdown package (Xie 2021) sample book, built top R Markdown knitr (Xie 2015).","code":""},{"path":"funcs-intro.html","id":"funcs-intro","chapter":"2 Functions: Introductory concepts","heading":"2 Functions: Introductory concepts","text":"","code":""},{"path":"funcs-intro.html","id":"software-requirements","chapter":"2 Functions: Introductory concepts","heading":"2.1 Software requirements","text":"","code":""},{"path":"funcs-intro.html","id":"r-packages","chapter":"2 Functions: Introductory concepts","heading":"2.1.1 R packages","text":"New: pbapplyAlready used: tidyverse, data.tableWe’ll sticking mostly base R functions int hsi chapter. also want show extra features considerations main data wrangling packages. per usual, run following code chunk install (necessary) load everything.","code":"\nif (!require(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(pbapply, data.table, tidyverse)"},{"path":"funcs-intro.html","id":"basic-syntax","chapter":"2 Functions: Introductory concepts","heading":"2.2 Basic syntax","text":"already seen used multitude functions R. functions come pre-packaged base R (e.g. mean()), others external packages (e.g. dplyr::filter()). Regardless come , functions R adopt basic syntax:much time, rely functions people written us. However, can — ! — write functions . easy generic function() function.1 syntax look familiar :’s possible reasonably common write anonymous functions like , typically write functions want reuse code. typical use-case makes sense name functions.2For short functions, don’t need invoke curly brackets assign explicit return object (). cases, can just write function single line:Try give functions short, pithy names informative anyone else reading code. harder sounds, pay road.","code":"\nfunction_name(ARGUMENTS)\nfunction(ARGUMENTS) {\n  OPERATIONS\n  return(VALUE)\n}\nmy_func = \n  function(ARGUMENTS) {\n    OPERATIONS\n    return(VALUE)\n  }\nmy_short_func = function(ARGUMENTS) OPERATION"},{"path":"funcs-intro.html","id":"a-simple-example","chapter":"2 Functions: Introductory concepts","heading":"2.3 A simple example","text":"Let’s write simple example function, gives square input number.Test .Great, works. Note simple example written everything single line; .e. square = function(x) x^2 work just well. (Confirm .) However, ’re add extra conditions options function, strongly favour multi-line format.Aside: want stress new square() function particularly exciting… , indeed, useful. R’s built-arithmetic functions already take care (vectorised) exponentiation efficiently. (See ?Arithmetic.) However, ’re going continue conceptually simple example, since provide clear framework demonstrating general principles functions R.","code":"\nsquare =        ## Our function name\n  function(x) { ## The argument(s) that our function takes as an input\n    x^2         ## The operation(s) that our function performs\n  }\nsquare(3)\n#> [1] 9"},{"path":"funcs-intro.html","id":"specifying-return-values","chapter":"2 Functions: Introductory concepts","heading":"2.3.1 Specifying return values","text":"Notice didn’t specify return value function. work many cases R’s default behaviour automatically return final object created within function. However, won’t always case. Opinions differ, recommendation get habit assigning return object(s) explicitly return(). Let’s modify function exactly ., test works.Specifying explicit return value also helpful want return one object. example, let’s say want remind user variable used argument function:Note multiple return objects combined list. didn’t name separate list elements — .e. “value” “value_squared” — helpful users function. Nevertheless, remember many objects R contain multiple elements (vectors, data frames, lists good examples ). can also specify one “array”-type objects within function provides convenient form output. example, combine input output values data frame:Test.","code":"\nsquare = \n  function(x) { \n    ## Create an intermediary object (that will be returned)\n    x_sq = x^2  \n    \n    ## The value(s) or object(s) that we want returned.\n    return(x_sq)  \n  }\nsquare(5)\n#> [1] 25\nsquare = \n  function(x) { \n    x_sq = x^2 \n    \n    ## The list of object(s) that we want returned.\n    return(list(value = x, value_squared = x_sq))\n  }\nsquare(3)\n#> $value\n#> [1] 3\n#> \n#> $value_squared\n#> [1] 9\nsquare = \n  function(x) { \n    x_sq = x^2 \n    \n    ## Bundle up our input and output values into a convenient dataframe.\n    d = data.frame(value=x, value_squared=x_sq) \n    \n    return(d)\n  }\nsquare(12)\n#>   value value_squared\n#> 1    12           144"},{"path":"funcs-intro.html","id":"specifying-default-argument-values","chapter":"2 Functions: Introductory concepts","heading":"2.3.2 Specifying default argument values","text":"Another thing worth noting R functions can assign default argument values. already encountered examples action.3 can add default option function pretty easily.’ll return issue specifying default values (handling invalid inputs) next lecture function debugging.","code":"\nsquare = \n  function(x = 1) { ## Setting the default argument value \n    x_sq = x^2 \n    d = data.frame(value = x, value_squared = x_sq)\n    \n    return(d)\n  }\nsquare()  ## Will take the default value of 1.\n#>   value value_squared\n#> 1     1             1\nsquare(2) ## Now takes the explicit value that we give it.\n#>   value value_squared\n#> 1     2             4"},{"path":"funcs-intro.html","id":"aside-environments-and-lexical-scoping","chapter":"2 Functions: Introductory concepts","heading":"2.3.3 Aside: Environments and lexical scoping","text":"continuing, want highlight fact none intermediate objects created within functions (x_sq, df, etc.) made way global environment. Take moment confirm looking “Environment” pane RStudio session.R set -called lexical scoping rules, govern stores evaluates values different objects. Without going much depth, practical implication lexical scoping functions operate quasi-sandboxed environment. don’t return use objects global environment unless forced (e.g. return() command). Similarly, function look outside environments (e.g. level “”) find object doesn’t see object named within .’ll explore ideas separate environments lexical scoping bit get Functional programming section . ’ll also go depth next lecture debugging.","code":""},{"path":"funcs-intro.html","id":"control-flow","chapter":"2 Functions: Introductory concepts","heading":"2.4 Control flow","text":"Now ’ve got good sense basic function syntax, ’s time learn control flow. , want control order (“flow”) statements operations functions evaluate.","code":""},{"path":"funcs-intro.html","id":"if-and-ifelse","chapter":"2 Functions: Introductory concepts","heading":"2.4.1 if and ifelse","text":"’ve already encountered conditional statements like () ifelse() numerous times course thus far.4 However, let’s see can work bespoke functions slightly modifying previous square function. time, instead specifying default input value 1 function argument , ’ll specify value NULL. ’ll use () statement reassign default one.go rigmarole specifying NULL default inpute ’re going change 1 anyway? Admittedly, pretty silly thing example. However, consider buys us next code chunk:time, specifying NULL argument — alongside expanded () statement — function now takes default value generates helpful message.5 Note use curly brackets conditional operations span multiple lines () statement.\nprovides nice segue ifelse() statements. ’ve already seen , written single conditional call format :Within functions, though ’re likely write several lines. Consider, example new function evaluates whether square() function job properly.","code":"\nsquare = \n  function(x = NULL) {  ## Default value of NULL\n    if (is.null(x)) x = 1 ## Re-assign default to 1\n    \n    x_sq = x^2 \n    d = data.frame(value = x, value_squared = x_sq)\n    \n    return(d)\n  }\nsquare()\n#>   value value_squared\n#> 1     1             1\nsquare = \n  function(x = NULL) {\n    \n    if (is.null(x)) { ## Start multi-line IF statement with `{`\n      x = 1\n      ## Message to users:\n      message(\"No input value provided. Using default value of 1.\")\n      }               ## Close multi-line if statement with `}`\n    \n    x_sq = x^2 \n    d = data.frame(value = x, value_squared = x_sq)\n    \n    return(d)\n  }\nsquare()\n#> No input value provided. Using default value of 1.\n#>   value value_squared\n#> 1     1             1ifelse(CONDITION, DO IF TRUE, DO IF FALSE)\neval_square =\n  function(x) {\n    \n    if (square(x)$value_squared == x*x) {\n      ## What to do if the condition is TRUE \n      message(\"Nailed it.\")\n    } else {\n      ## What to do if the condition is FALSE\n      message(\"Dude, your function sucks.\")\n    }\n    \n  }\neval_square(64)\n#> Nailed it."},{"path":"funcs-intro.html","id":"aside-ifelse-gotchas-and-alternatives","chapter":"2 Functions: Introductory concepts","heading":"2.4.1.1 Aside: ifelse gotchas and alternatives","text":"base R ifelse() function normally works great use time. However, couple “gotcha” cases aware . Consider following (silly) function designed return either today’s date, day .doubt surprised find function returns number instead date. ifelse() automatically converts date objects numeric way get around type conversion strictures. Confirm converting back way around : .Date(today(TRUE), origin = \"1970-01-01\").Aside: “dot-dot-dot” argument (...) ’ve used convenient shortcut allows users enter unspecified arguments function. beyond scope current lecture, can prove incredibly useful flexible programming strategy. highly encourage look relevant section Advanced R get better idea.guard type unexpected behaviour, well incorporate optimisations, tidyverse (dplyr) data.table offer versions ifelse statements. won’t explain next code chunks depth (consult relevant help pages needed), adapted versions today() function based alternatives.First, dplyr::if_else():Second, data.table::fifelse():","code":"\ntoday = function(...) ifelse(..., Sys.Date(), Sys.Date()-1)\ntoday(TRUE)\n#> [1] 18730\ntoday2 = function(...) dplyr::if_else(..., Sys.Date(), Sys.Date()-1)\ntoday2(TRUE)\n#> [1] \"2021-04-13\"\ntoday3 = function(...) data.table::fifelse(..., Sys.Date(), Sys.Date()-1)\ntoday3(TRUE)\n#> [1] \"2021-04-13\""},{"path":"funcs-intro.html","id":"case-when-nested-ifelse","chapter":"2 Functions: Introductory concepts","heading":"2.4.2 case when (nested ifelse)","text":"may guessed, ’s certainly possible write nested ifelse() statements. example,However, nested statements quickly become difficult read troubleshoot. better solution originally developed SQL CASE statement. dplyr case_when() data.table fcase() provide implementations R. simple illustration implementations.belabour point, can easily use case implementations inside data frames/tables .","code":"ifelse(CONDITION1, DO IF TRUE, ifelse(CONDITION2, DO IF TRUE, ifelse(...)))\nx = 1:10\n\n## dplyr::case_when()\ncase_when(\n  x <= 3 ~ \"small\",\n  x <= 7 ~ \"medium\",\n  TRUE ~ \"big\" ## Default value. Could also write `x > 7 ~ \"big\"` here.\n  )\n#>  [1] \"small\"  \"small\"  \"small\"  \"medium\" \"medium\" \"medium\" \"medium\" \"big\"   \n#>  [9] \"big\"    \"big\"\n\n## data.table::fcase()\nfcase(\n    x <= 3, \"small\",\n    x <= 7, \"medium\",\n    default = \"big\" ## Default value. Could also write `x > 7, \"big\"` here.\n    )\n#>  [1] \"small\"  \"small\"  \"small\"  \"medium\" \"medium\" \"medium\" \"medium\" \"big\"   \n#>  [9] \"big\"    \"big\"\n## dplyr::case_when()\ndata.frame(x = 1:10) %>%\n    mutate(grp = case_when(x <= 3 ~ \"small\",\n                           x <= 7 ~ \"medium\",\n                           TRUE ~ \"big\"))\n#>     x    grp\n#> 1   1  small\n#> 2   2  small\n#> 3   3  small\n#> 4   4 medium\n#> 5   5 medium\n#> 6   6 medium\n#> 7   7 medium\n#> 8   8    big\n#> 9   9    big\n#> 10 10    big\n## data.table::fcase()\ndata.table(x = 1:10)[, grp := fcase(x <= 3, \"small\",\n                                    x <= 7, \"medium\",\n                                    default = \"big\")][]\n#>      x    grp\n#>  1:  1  small\n#>  2:  2  small\n#>  3:  3  small\n#>  4:  4 medium\n#>  5:  5 medium\n#>  6:  6 medium\n#>  7:  7 medium\n#>  8:  8    big\n#>  9:  9    big\n#> 10: 10    big"},{"path":"funcs-intro.html","id":"iteration","chapter":"2 Functions: Introductory concepts","heading":"2.5 Iteration","text":"Alongside control flow, important early programming skill master iteration. particular, want write functions can iterate — map — set inputs.6 far common way iterate across different programming languages loops. Indeed, already saw examples loops back shell lecture (see ). However, R certainly accepts standard loops, ’m going advocate adopt known “functional programming” approach writing loops. Let’s dive reasons approaches differ.","code":""},{"path":"funcs-intro.html","id":"vectorisation","chapter":"2 Functions: Introductory concepts","heading":"2.5.1 Vectorisation","text":"first question need ask : “need iterate ?” may remember previous lecture spoke R vectorised. means can apply function entire vector, rather explicitly iterating element.7 Let’s demonstrate property square function:may need worry explicit iteration . said, certainly cases need worry . Let’s explore simple examples (already vectorised) provide mental springboard thinking complex cases.","code":"\nsquare(1:5)\n#>   value value_squared\n#> 1     1             1\n#> 2     2             4\n#> 3     3             9\n#> 4     4            16\n#> 5     5            25\nsquare(c(2, 4))\n#>   value value_squared\n#> 1     2             4\n#> 2     4            16"},{"path":"funcs-intro.html","id":"for-loops","chapter":"2 Functions: Introductory concepts","heading":"2.5.2 for loops","text":"R, standard loops take pretty intuitive form. example:Note cases want “grow” object via loop, first create empty (NULL) object.Unfortunately, basic loops R also come downsides. Historically, used significantly slower memory consumptive alternative methods (see ). largely resolved, ’ve still run cases inconspicuous loop brought entire analysis crashing knees.8 bigger problem loops, however, deviate norms best practices functional programming.","code":"\nfor(i in 1:10) print(LETTERS[i])\n#> [1] \"A\"\n#> [1] \"B\"\n#> [1] \"C\"\n#> [1] \"D\"\n#> [1] \"E\"\n#> [1] \"F\"\n#> [1] \"G\"\n#> [1] \"H\"\n#> [1] \"I\"\n#> [1] \"J\"\nkelvin = 300:305\nfahrenheit = NULL\n# fahrenheit = vector(\"double\", length(kelvin)) ## Better than the above. Why?\nfor(k in 1:length(kelvin)) {\n  fahrenheit[k] = kelvin[k] * 9/5 - 459.67\n}\nfahrenheit\n#> [1] 80.33 82.13 83.93 85.73 87.53 89.33"},{"path":"funcs-intro.html","id":"functional-programming","chapter":"2 Functions: Introductory concepts","heading":"2.5.3 Functional programming","text":"concept functional programming (FP) arguably important thing can take away chapter. excellent book, Advanced R, Hadley Wickham explains core idea follows.R, heart, functional programming (FP) language. means provides many tools creation manipulation functions. particular, R ’s known first class functions. can anything functions can vectors: can assign variables, store lists, pass arguments functions, create inside functions, even return result function.may seem little abstract, video Hadley giving much intuitive explanation series examples.Summary: loops tend emphasise objects ’re working (say, vector numbers) rather operations want apply (say, get mean median whatever). inefficient requires us continually write loops hand rather getting R function create -loop us.corollary, loops also pollute global environment variables used counting variables. Take look “Environment” pane RStudio. see? addition kelvin fahrenheit vectors created, also see two variables k (equal last value respective loops). Creating auxiliary variables almost certainly intended outcome write -loop.9 worringly, can cause programming errors inadvertently refer similarly-named variable elsewhere script. best remove manually soon ’re finished loop.Another annoyance arrived cases want “grow” object iterate (e.g. fahrenheit object second example). order loop, go rigmarole creating empty object first.FP allows avoid explicit use loop constructs associated downsides. practice, two ways implement FP R:*apply family functions base R.map*() family functions purrr.Let’s explore depth.","code":"\nrm(i, k)"},{"path":"funcs-intro.html","id":"lapply-and-co.","chapter":"2 Functions: Introductory concepts","heading":"2.5.3.1 lapply and co.","text":"Base R contains useful family *apply functions. won’t go — see ?apply blog post among numerous excellent resources — follow similar philosophy syntax. good news syntax closely mimics syntax basic -loops. example, consider code , analgous first loop , now invokes base::lapply() call instead.couple things notice.First, check “Environment” pane RStudio. see object called “” Global Environment? (answer “.”) , R’s lexical scoping rules, mean object created invoked function evaluated sandboxed environment outside global environment.Second, notice little basic syntax changed switching () lapply(). Yes, differences, essential structure remains : first provide iteration list (1:10) specify desired function operation (LETTERS[]).Third, notice returned object list. lapply() function can take various input types arguments — vectors, data frames, lists — always returns list, element returned list result one iteration loop. (now know “l” “lapply” comes .)","code":"\n# for(i in 1:10) print(LETTERS[i]) ## Our original for loop (for comparison)\nlapply(1:10, function(i) LETTERS[i])\n#> [[1]]\n#> [1] \"A\"\n#> \n#> [[2]]\n#> [1] \"B\"\n#> \n#> [[3]]\n#> [1] \"C\"\n#> \n#> [[4]]\n#> [1] \"D\"\n#> \n#> [[5]]\n#> [1] \"E\"\n#> \n#> [[6]]\n#> [1] \"F\"\n#> \n#> [[7]]\n#> [1] \"G\"\n#> \n#> [[8]]\n#> [1] \"H\"\n#> \n#> [[9]]\n#> [1] \"I\"\n#> \n#> [[10]]\n#> [1] \"J\""},{"path":"funcs-intro.html","id":"aside-binding-and-simplifying-lists","chapter":"2 Functions: Introductory concepts","heading":"2.5.3.2 Aside: Binding and simplifying lists","text":"Okay, don’t want iteration output remain list form? several options , depending type output want (vector, data frame, etc.) Like social scientists, imagine, preferred data structure data frame. , typically want bind different list elements single data frame. three simple ways :Base R: .call(\"rbind\")dplyr: bind_rows()data.table: rbindlist()three options choose largely matter taste constraints. feel like loading package? (, go .call(\"rbind\").) performance paramount? (yes, go data.table::rbindlist()). part think . example, ’s slightly modified version previous function now yields data frame:Taking step back — default list-return behaviour may sound ideal first — find use lapply() frequently apply family members. key reason functions often return multiple objects different type (makes lists sensible format). , return single data frame (.call(\"rbind\") co. enter picture).’s worth, another option work well present particular case sapply(). stands “simplify apply” essentially wrapper around lapply tries return simplified output matches input type. , try return vector vector, etc. example:","code":"\nlapply(1:10, function(i) data.frame(num = i, let = LETTERS[i])) %>%\n  # do.call(\"rbind\", .)      ## Also works\n  # data.table::rbindlist()  ## Ditto\n  dplyr::bind_rows()\n#>    num let\n#> 1    1   A\n#> 2    2   B\n#> 3    3   C\n#> 4    4   D\n#> 5    5   E\n#> 6    6   F\n#> 7    7   G\n#> 8    8   H\n#> 9    9   I\n#> 10  10   J\nsapply(1:10, function(i) LETTERS[i]) \n#>  [1] \"A\" \"B\" \"C\" \"D\" \"E\" \"F\" \"G\" \"H\" \"I\" \"J\""},{"path":"funcs-intro.html","id":"aside-progress-bars","chapter":"2 Functions: Introductory concepts","heading":"2.5.3.2.1 Aside: Progress bars!","text":"doesn’t like progress bars? Personally, find incredibly helpful see function progressing, get sense much longer can expect wait completion.Along lines, ’m big fan pbapply package, lightweight wrapper around *apply functions adds progress bar. pbapply offers versions *apply family, one use (unsurprisingly) pbapply::pblapply().Note: need run next example interactively see effect properly.Another thing really like pblapply() function allows easy implementation parallel (.e. multicore) processing works across operating systems. ’ll cover next week, though.’s also newish package scene, progressr, provides unified API progress updates across multiple iteration frameworks R. won’t cover , ’s pretty neat simple use, check .","code":"\n# library(pbapply) ## Already loaded\n\npblapply(1:10, function(i) {\n  d = data.frame(num = i, let = LETTERS[i])\n  Sys.sleep(1)\n  return(d)\n  }) %>%\n  bind_rows()\n#>    num let\n#> 1    1   A\n#> 2    2   B\n#> 3    3   C\n#> 4    4   D\n#> 5    5   E\n#> 6    6   F\n#> 7    7   G\n#> 8    8   H\n#> 9    9   I\n#> 10  10   J"},{"path":"funcs-intro.html","id":"purrr-package","chapter":"2 Functions: Introductory concepts","heading":"2.5.3.3 purrr package","text":"tidyverse offers enhanced implementation base *apply() functions purrr package.10 key function remember purrr::map(). , indeed, syntax output command effectively identical base::lapply():Given similarities, won’t spend much time purrr. Although, think optimal entry point many comes programming iteration. already learned syntax, easy switch . However, one additional thing wanted flag now fact map() also comes variants, useful returning objects desired type. example, can use purrr::map_df() return data frame.Note efficient (.e. involves less typing) lapply() version, since don’t go extra step binding rows end.","code":"\nmap(1:10, function(i) { ## only need to swap `lapply` for `map`\n  d = data.frame(num = i, let = LETTERS[i])\n  return(d)\n  })\n#> [[1]]\n#>   num let\n#> 1   1   A\n#> \n#> [[2]]\n#>   num let\n#> 1   2   B\n#> \n#> [[3]]\n#>   num let\n#> 1   3   C\n#> \n#> [[4]]\n#>   num let\n#> 1   4   D\n#> \n#> [[5]]\n#>   num let\n#> 1   5   E\n#> \n#> [[6]]\n#>   num let\n#> 1   6   F\n#> \n#> [[7]]\n#>   num let\n#> 1   7   G\n#> \n#> [[8]]\n#>   num let\n#> 1   8   H\n#> \n#> [[9]]\n#>   num let\n#> 1   9   I\n#> \n#> [[10]]\n#>   num let\n#> 1  10   J\nmap_df(1:10, function(i) { ## don't need bind_rows with `map_df`\n  d = data.frame(num = i, let = LETTERS[i])\n  return(d)\n  })\n#>    num let\n#> 1    1   A\n#> 2    2   B\n#> 3    3   C\n#> 4    4   D\n#> 5    5   E\n#> 6    6   F\n#> 7    7   G\n#> 8    8   H\n#> 9    9   I\n#> 10  10   J"},{"path":"funcs-intro.html","id":"create-and-iterate-over-named-functions","chapter":"2 Functions: Introductory concepts","heading":"2.5.4 Create and iterate over named functions","text":"may guessed already, can split function iteration (binding) separate steps. generally good idea, since typically create (named) functions goal reusing .Now, can easily iterate function using different input values. example,, say","code":"\n## Create a named function\nnum_to_alpha = \n  function(i) {\n  d = data.frame(num = i, let = LETTERS[i])\n  return(d)\n  }\nlapply(1:10, num_to_alpha) %>% bind_rows()\n#>    num let\n#> 1    1   A\n#> 2    2   B\n#> 3    3   C\n#> 4    4   D\n#> 5    5   E\n#> 6    6   F\n#> 7    7   G\n#> 8    8   H\n#> 9    9   I\n#> 10  10   J\nmap_df(c(1, 5, 26, 3), num_to_alpha)\n#>   num let\n#> 1   1   A\n#> 2   5   E\n#> 3  26   Z\n#> 4   3   C"},{"path":"funcs-intro.html","id":"iterate-over-multiple-inputs","chapter":"2 Functions: Introductory concepts","heading":"2.5.5 Iterate over multiple inputs","text":"Thus far, working functions take single input iterating. example, feed single vector (even though vector contains many elements drive iteration process). want iterate multiple inputs? Consider following function, takes two separate variables x y inputs, combines data frame, uses create third variable z.Note: , rather silly function easily improve upon using standard (vectorised) tools. goal demonstrate programming principles simple examples carry complicated cases vectorisation possible.continuing, quickly test works using non-iterated inputs.Great, works. Now let’s imagine want iterate various levels x y. two basics approaches can follow achieve :Use base::mapply()/base::Map() purrr::pmap().Use data frame input combinations.’ll quickly review approaches, continuing multi_func() function just created .","code":"\n## Create a named function\nmulti_func = \n  function(x, y) {\n    z = (x + y) / sqrt(x)\n    data.frame(x, y, z)\n  }\nmulti_func(1, 6)\n#>   x y z\n#> 1 1 6 7"},{"path":"funcs-intro.html","id":"use-mapplymap-or-pmap","chapter":"2 Functions: Introductory concepts","heading":"2.5.5.1 Use mapply()/Map() or pmap()","text":"base R — mapply()/Map() — purrr — pmap — can handle multiple input cases iteration. latter easier work opinion, since syntax closer (nearly identical) single input case. Still, ’ll demonstrate using versions .First, base::mapply():Note: don’t feel like typing SIMPLIFY = FALSE, Map() light wrapper around mapply() automatically. Try slightly editing function use Map() instead mapply().Second, purrr::pmap():","code":"\n## Note that the inputs are now moved to the *end* of the call. Also, mapply() \n## is based on sapply(), so we also have to tell it not to simplify if we want \n## to keep the list structure.\nmapply(\n  multi_func,\n  x = 1:5,         ## Our \"x\" vector input\n  y = 6:10,        ## Our \"y\" vector input\n  SIMPLIFY = FALSE ## Tell it not to simplify to keep the list structure\n  ) %>%\n  do.call(\"rbind\", .)\n#>   x  y        z\n#> 1 1  6 7.000000\n#> 2 2  7 6.363961\n#> 3 3  8 6.350853\n#> 4 4  9 6.500000\n#> 5 5 10 6.708204\n## Note that the function inputs are combined in a list and come first.\npmap_df(\n  list(x = 1:5, y = 6:10), \n  multi_func\n  )\n#>   x  y        z\n#> 1 1  6 7.000000\n#> 2 2  7 6.363961\n#> 3 3  8 6.350853\n#> 4 4  9 6.500000\n#> 5 5 10 6.708204"},{"path":"funcs-intro.html","id":"using-a-data-frame-of-input-combinations","chapter":"2 Functions: Introductory concepts","heading":"2.5.5.2 Using a data frame of input combinations","text":"approaches work perfectly well, find don’t actually use either much practice. Rather, prefer “cheat” feeding multi-input functions single data frame specifies necessary combination variables row. ’ll demonstrate works second, first let explain .basically boils fact feel gives control functions inputs.don’t worry accidentally feeding separate inputs different lengths. Try running functions x vector input 1:10, example. (Leave everything else unchanged.) pmap() least fail iterate give helpful message, mapply actually complete totally misaligned columns. Putting everything (rectangular) data frame forces ensure equal length inputs priori.Similarly, often need run function possible combinations different inputs.11 ’s convenient use data frame input directly function.view, ’s just simpler cleaner keep things single input. harder see simple example ’m going present next. ’ve found can make big difference complicated functions lot nesting (.e. functions functions) /parallelization.justifications aside, let’s see might work example. Consider following function:three conceptual steps code chunk:First, create new function called parent_func(), takes single input: data frame containing x y columns (potentially columns ).input data frame passed second (nested) function, iterate rows data frame.iteration, x y values row passed original multi_func() function. return data frame containing desired output.Let’s test worked using two different input data frames.","code":"\nparent_func =\n  ## Main function: Takes a single data frame as an input\n  function(input_df) {\n    d =\n      ## Nested iteration function\n      map_df(\n      1:nrow(input_df), ## i.e. Iterate (map) over each row of the input data frame\n      function(n) {\n        ## Extract the `x` and `y` values from row \"n\" of the data frame\n        x = input_df$x[n]\n        y = input_df$y[n]\n        ## Apply our function on the the extracted values\n        multi_func(x, y)\n      })\n    return(d)\n    }\n## Case 1: Iterate over x=1:5 and y=6:10\ninput_df1 = data.frame(x = 1:5, y = 6:10)\nparent_func(input_df1)\n#>   x  y        z\n#> 1 1  6 7.000000\n#> 2 2  7 6.363961\n#> 3 3  8 6.350853\n#> 4 4  9 6.500000\n#> 5 5 10 6.708204\n\n## Case 2: Iterate over *all possible combinations* of x=1:5 and y=6:10\ninput_df2 = expand.grid(x = 1:5, y = 6:10)\nparent_func(input_df2)\n#>    x  y         z\n#> 1  1  6  7.000000\n#> 2  2  6  5.656854\n#> 3  3  6  5.196152\n#> 4  4  6  5.000000\n#> 5  5  6  4.919350\n#> 6  1  7  8.000000\n#> 7  2  7  6.363961\n#> 8  3  7  5.773503\n#> 9  4  7  5.500000\n#> 10 5  7  5.366563\n#> 11 1  8  9.000000\n#> 12 2  8  7.071068\n#> 13 3  8  6.350853\n#> 14 4  8  6.000000\n#> 15 5  8  5.813777\n#> 16 1  9 10.000000\n#> 17 2  9  7.778175\n#> 18 3  9  6.928203\n#> 19 4  9  6.500000\n#> 20 5  9  6.260990\n#> 21 1 10 11.000000\n#> 22 2 10  8.485281\n#> 23 3 10  7.505553\n#> 24 4 10  7.000000\n#> 25 5 10  6.708204"},{"path":"funcs-intro.html","id":"further-resources","chapter":"2 Functions: Introductory concepts","heading":"2.6 Further resources","text":"next two lectures, ’ll dive advanced programming function topics (debugging, parallel implementation, etc.). However, hope chapter given solid grasp fundamentals. highly encourage start writing functions. lot career progresses. Establishing early mastery function writing put road awesome data science successTM. additional resources inspiration reference:Garrett Grolemund Hadley Wickham’s R Data Science book — esp. chapters 19 (“Functions)”) 21 (“Iteration)”) — covers much ground , particular emphasis purrr package iteration.’re looking -depth treatment, can highly recommend Hadley’s Advanced R (2nd ed.) provides detailed yet readable overview concepts touched chapter, including (R’s) philosophy regarding functional programming (see Section ||).’re market concise overview different *apply() functions, recommend blog post Neil Saunders.end scale, Jenny Bryan (hail) created fairly epic purrr tutorial mini-website. (Bonus: goes depth working lists list columns.)","code":""},{"path":"funcs-intro.html","id":"bonus-accessing-function-source-code","chapter":"2 Functions: Introductory concepts","heading":"2.7 Bonus: Accessing function source code","text":"Looking inside function important debugging (.e. subject next lecture), ’s also great way pick programming tips tricks. refer accessing function’s source code. simple functions, accessing source mere matter typing function name R console (without parentheses) letting R print object screen. Try num_to_alpha function created earlier, , say, dplyr::bind_rows.Unfortunately, simple print-function--screen approach doesn’t work start getting functions different dispatch methods (e.g. associated S3 S4 classes), rely compiled code underneath hood (e.g. written C Fortran). good news can still view source code, even sometimes requires bit legwork. See Joshua Ulrich’s StackOverflow Q/, Jenny Bryan’s summary . Lastly, Jim Hester’s lookup package can legwork don’t feel like dealing complications.","code":""},{"path":"funcs-adv.html","id":"funcs-adv","chapter":"3 Functions: Advanced concepts","heading":"3 Functions: Advanced concepts","text":"","code":""},{"path":"funcs-adv.html","id":"software-requirements-1","chapter":"3 Functions: Advanced concepts","heading":"3.1 Software requirements","text":"","code":""},{"path":"funcs-adv.html","id":"r-packages-1","chapter":"3 Functions: Advanced concepts","heading":"3.1.1 R packages","text":"New: memoiseAlready used: tidyverse, hereInstall (necessary) load packages now:also working simple square() function Chapter 2. Let’s create quickly.","code":"\nif (!require(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(memoise, tidyverse, here)\nsquare = \n  function(x = 1) {\n    x_sq = x^2 \n    d = data.frame(value = x, value_squared = x_sq)\n    return(d)\n  }"},{"path":"funcs-adv.html","id":"debugging","chapter":"3 Functions: Advanced concepts","heading":"3.2 Debugging","text":"Functions incredibly powerful helpful programming tools. also tend go wrong lot. Sometimes (someone else) made mistake writing code. Othertimes user error (e.g. invalid inputs). Regardless, begin debugging code figure things went wrong.","code":""},{"path":"funcs-adv.html","id":"debugging-tools-in-rstudio","chapter":"3 Functions: Advanced concepts","heading":"3.2.1 Debugging tools in RStudio","text":"R RStudio IDE provide number excellent tools debugging. ’ll walk together series live coding examples minute. , first visual summary, cropped directly RStudio IDE Cheat Sheet.12","code":""},{"path":"funcs-adv.html","id":"debug-mode","chapter":"3 Functions: Advanced concepts","heading":"3.2.2 Debug mode","text":"Note: section run interactively ’ve set code chunks eval=FALSE R Markdown document. don’t surprised knitted HTML document doesn’t contain output corresponding ’m talking text. advice run code chunks follow along text.figure suggests, various ways enter -called debug mode. “step inside” function evaluate objects within function environment. words, allows pause time interact internal function objects normally hidden global environment.13 Let’s practice example.Suppose feed deliberately invalid input — .e. character string — square() function:Now, course, already knew function call fail. (D’uh, can’t square string.) case, R also produced informative error message. However, notice don’t actually get see point failure — .e. line code function tried square value “one.” need enter debug mode.several ways trigger debugger, recommend debugonce() function. name suggests, running debugonce(square) cause us enter debug mode next time call square(), one time.14 Let’s try live session:screenshot computer ran code chunk explored little.Note following changes RStudio IDE ’m debug mode:Source (top-left). new “square” debugger script popped . green arrow highlighted text indicates line function run next.Environment (top-right). ’m longer Global Environment, rather inside “square()” function environment.\none object inside function environment: variable x (.e. function argument) assigned value “one.”\nAlso note new Traceback window pane . traceback (“call stack”) tells code ’ve done get point. traceback stack add much value simple functions like , can informative longer complicated functions.\none object inside function environment: variable x (.e. function argument) assigned value “one.”Also note new Traceback window pane . traceback (“call stack”) tells code ’ve done get point. traceback stack add much value simple functions like , can informative longer complicated functions.Console (bottom-right). prompt changed > Browse[2]>, indicating now R environment browser. debugger console fully functional started exploring.\nseveral control buttons across top (“Next,” “Continue,” “Stop,” etc.), allow walk code different ways.\n’ve manually entered x console prompt confirmed R returns value “one.”\nimportantly: tried running first line function (x_sq = x^2) met error message (“non-numeric argument binary operator”). exact point function actually fails.\nseveral control buttons across top (“Next,” “Continue,” “Stop,” etc.), allow walk code different ways.’ve manually entered x console prompt confirmed R returns value “one.”importantly: tried running first line function (x_sq = x^2) met error message (“non-numeric argument binary operator”). exact point function actually fails.Now, , case particular case problem obvious known ahead time. think simple example useful illustrating general debugging principles power able step inside functions via debugger mode. gives chance see functions “sees” work root cause problem systematic way. identified problem, can set correcting function (inputs). Ultimately, want write robust functions recognise errors early, fail acceptable level tolerance, provide helpful feedback users. subject next section.","code":"\nsquare(\"one\")\n#> Error in x^2: non-numeric argument to binary operator\n## Run this next chunk yourself in a live session\ndebugonce(square)\nsquare(\"one\")"},{"path":"funcs-adv.html","id":"aside-manual-vs-prompted-debugging","chapter":"3 Functions: Advanced concepts","heading":"3.2.3 Aside: Manual vs prompted debugging","text":"First, aside: don’t always manually invoke debugger function fails. example, debugonce(). fact, RStudio often prompt “Rerun Debug” automatically something goes wrong. see something like screenshot console happens. (Ignore specific function error message rather focus blue icons right.)automatic RStudio prompt arise whenever something wrong way R code function evaluated (.e. yields R error). contrast, won’t receive automatic prompt something wrong code logic (e.g. try square character string).","code":""},{"path":"funcs-adv.html","id":"catching-user-errors","chapter":"3 Functions: Advanced concepts","heading":"3.3 Catching user errors","text":"previous chapter, implicitly assumed user knows exactly use function. However, isn’t always case. related, complicated, case mistakenly input wrong type argument function. Let’s return earlier example, “accidentally” entered string square() function.may just seem like case particularly dumb user error. However — trust — easy run category problem complex analysis consists , say, series nested functions. (One function calling another, calling another…) whatever reason, single function iteration may produce slightly different output expected can bring entire analysis crashing knees, output can’t used next part chain. especially frustrating running multicore process (e.g. parallel Monte Carlo simulation), since program first complete entire run — perhaps taking several hours — informing right end error somewhere results (even valid iterations!) retained.Luckily, several approaches guarding kind mistakes. ’ll briefly run see three main options .Function-specific control flowUse base::tryCatch()Use purrr::safely() family","code":"\nsquare(\"one\") \n#> Error in x^2: non-numeric argument to binary operator"},{"path":"funcs-adv.html","id":"function-specific-control-flow","chapter":"3 Functions: Advanced concepts","heading":"3.3.1 Function-specific control flow","text":"covered basics control flow Chapter 2. Let’s put concepts use debugging. particular function, example, know function requires numeric input. can check whether input argument numeric use ifelse statement produce warning/error message fails test. Consider, , slightly modified version function, ’ll call square_ifelse.Test .can achieve similar result, less code, using generic stop() function.","code":"\nsquare_ifelse = \n  function (x = 1) { \n    if (is.numeric(x)) { ## Check valid argument to our function.\n      x_sq = x^2 \n      d = data.frame(value = x, value_squared = x_sq)\n      return(d) \n    } else {             ## Return a warning message if not.\n      message(\"Sorry, you need to provide a numeric input variable.\")\n    }\n  }\nsquare_ifelse(\"one\") ## Will trigger our warning message.\n#> Sorry, you need to provide a numeric input variable.\nsquare_ifelse(1) ## Works.\n#>   value value_squared\n#> 1     1             1\nsquare_stop = \n  function (x = 1) { \n    if (!is.numeric(x)) stop(\"Sorry, you need to provide a numeric input variable.\")\n    x_sq = x^2 \n    d = data.frame(value = x, value_squared = x_sq)\n    return(d) \n  }\nsquare_stop(\"one\") ## Triggers a stop error and warning\n#> Error in square_stop(\"one\"): Sorry, you need to provide a numeric input variable.\nsquare_stop(1) ## Works\n#>   value value_squared\n#> 1     1             1"},{"path":"funcs-adv.html","id":"use-basetrycatch","chapter":"3 Functions: Advanced concepts","heading":"3.3.2 Use base::tryCatch()","text":"Another, general option use base::tryCatch() function handling errors warnings. Let demonstrate usefulness two separate examples.","code":""},{"path":"funcs-adv.html","id":"wrap-trycatch-around-an-entire-function","chapter":"3 Functions: Advanced concepts","heading":"3.3.2.1 Wrap tryCatch() around an entire function","text":"first simply wraps generic tryCatch statement around existing square function. Note invocation R’s -built “error” class, turn passed another -built function called message. Basically, telling R produce particular message whenever recognizes error (error!) occurred executing bespoke function.first example works well, downside throwing everything went function favour single error message. , throw potentially valid input-output single error. see clearly, let’s feed function vector inputs, one input invalid.simply get error message, even though () inputs valid. ideal world, retained input-output valid parameters (.e. 1 2) received error message single invalid case (.e. “three”). leads us second example…","code":"\ntryCatch(\n  square(\"three\"), \n  error = function(e) message(\"Oops. Did you try to square a string instead of a number?\")\n  )\n#> Oops. Did you try to square a string instead of a number?\ntryCatch(\n  square(c(1,2,\"three\")), \n  error = function(e) message(\"Oops. Did you try to square a string instead of a number?\")\n  )\n#> Oops. Did you try to square a string instead of a number?"},{"path":"funcs-adv.html","id":"use-trycatch-inside-a-function","chapter":"3 Functions: Advanced concepts","heading":"3.3.2.2 Use tryCatch() inside a function","text":"second example avoids problem invoking tryCatch() inside user-defined function. principle much : ’re going tell R give us whenever encounters error. However, going explicit expect error occur. Moreover, instead simply producing error message, time ’ll instruct R return explicit, alternative value (.e. NA).Let’s see works previous input vector, one input invalid.Huh? Looks like half worked. get input values, now squared values converted NA. think ? Challenge: See can figure problem using debugonce(square_trycatch) continuing…Let’s take deeper look input vector:Ah-ha. R coerced every element input vector character string. (Remember: Vectors can contain elements type.) solution use input array allows different element types — .e. list. , turn, requires modifying way invoke function putting base::lapply() purrr::map() call. ’ll hopefully remember Chapter 2, two functions syntactically identical, ’ll just use latter:practiced previous chapter, may wish bind resulting list data frames single data frame using dplyr::bind_rows() , simply, purrr::map_df(). However, actually produces errors columns need .somewhat pedantic solution make sure offending input coerced numeric within function . Note introduce coercion warnings , least won’t fail.","code":"\nsquare_trycatch =\n  function (x = 1) {\n    ## tryCatch goes here now. Produce an NA value if we can't square the input.\n    x_sq = tryCatch(x^2, error = function(e) NA_real_) \n    \n    d = data.frame(value = x, value_squared = x_sq)\n    \n    return(d)\n  }\nsquare_trycatch(c(1, 2, \"three\"))\n#>   value value_squared\n#> 1     1            NA\n#> 2     2            NA\n#> 3 three            NA\nstr(c(1, 2, \"three\"))\n#>  chr [1:3] \"1\" \"2\" \"three\"\nmap(list(1, 2, \"three\"),  square_trycatch) \n#> [[1]]\n#>   value value_squared\n#> 1     1             1\n#> \n#> [[2]]\n#>   value value_squared\n#> 1     2             4\n#> \n#> [[3]]\n#>   value value_squared\n#> 1 three            NA\nmap_df(list(1, 2, \"three\"),  square_trycatch)\n#> Error: Can't combine `..1$value` <double> and `..3$value` <character>.\nsquare_trycatch2 =\n  function (x = 1) {\n    x_sq = tryCatch(x^2, error = function(e) NA_real_) \n    \n    ## Convert input to numeric\n    d = data.frame(value = as.numeric(x), value_squared = x_sq)\n    \n    return(d)\n  }\n\nmap_df(list(1, 2, \"three\"), square_trycatch2)\n#> Warning in data.frame(value = as.numeric(x), value_squared = x_sq): NAs\n#> introduced by coercion\n#>   value value_squared\n#> 1     1             1\n#> 2     2             4\n#> 3    NA            NA"},{"path":"funcs-adv.html","id":"use-purrrsafely-and-family","chapter":"3 Functions: Advanced concepts","heading":"3.3.3 Use purrr::safely() and family","text":"Finally, prefer tidyverse equivalent tryCatch(), can use purrr::safely() related functions (including purrr::possibly() variants). won’t go entire rigmarole , ’s simple flavour work:can also specify default behaviour case error:","code":"\nsquare_simple =\n  function (x = 1) {\n    x_sq = x^2\n  }\nsquare_safely = safely(square_simple)\nsquare_safely(\"three\")\n#> $result\n#> NULL\n#> \n#> $error\n#> <simpleError in x^2: non-numeric argument to binary operator>\nsquare_safely = safely(square_simple, otherwise = NA_real_)\nsquare_safely(\"three\")\n#> $result\n#> [1] NA\n#> \n#> $error\n#> <simpleError in x^2: non-numeric argument to binary operator>"},{"path":"funcs-adv.html","id":"caching-memoisation","chapter":"3 Functions: Advanced concepts","heading":"3.4 Caching (memoisation)","text":"’ve ever used R Markdown, ’ve already experienced benefits (occasional frustrations) caching. Caching can also extremely useful regular R scripts analyses. example, may wish save computationally-expensive output don’t run . related sinister note, programs functions can crash midway completion. can happen variety reasons: invalid function arguments buried iterated input, computer malfunction, memory limits, power outages, timeouts, etc. Regardless, can fairly soul-splintering experience lose work ’re working particularly lengthy simulation computation problem.’ll get parallel computation next chapter, problem even worse . typically happens parallelized program entire run complete (potentially taking many hours days) reveal error right end… saved output!Fortunately, R back several caching tools. ’m going focus memoise package (link). Note memoisation/memoization refers particular form caching save (.e. “remember”) results expensive functions calls, don’t repeat future.Let’s start creating “slow” version simple square function — waits two seconds anything — ’ll creatively call slow_square(). course, just meant emulate computationally-expensive operation, basic principles carry intact.Enabling caching (.e. memoisation) slow function simple matter feeding memoise::memoise().Note: ’ve assigned memoised version function (.e. mem_square()). However, ’s problem recycle original function name prefer (.e. slow_square = memoise(slow_square)).first time execute memoised slow_square_mem() function, won’t able draw saved results. means run underlying computation. process , however, save inputs results immediate retrieval later .Let’s run examples compare actual timings. first run, ’ll iterate function using numbers 1 10 save resulting data frame object called m1.expected took 20 seconds enforced two second wait iteration. Now, try calling function second time — iterating exact inputs saving new m2 object — see caching makes difference…ever! ’re fraction second, since didn’t need run . Rather, simply recalled previously saved (.e. memoised) results. just prove ’re really saving meaningful output, comparison two data frames, well printed output m2.Finally, note caching function smart enough distinguish previously cached non-cached results. example, consider happens include five numbers x input vector.expected, took (5 \\(\\times\\) 2 = ) 10 seconds generate new results scratch, previous results called cache. can think preceding example approximating real-life scenario, program crashes halts midway run, yet don’t need restart way beginning. kinds interruptions happen frequently might expect, especially ’re working complex analyses high-performance computing tools (e.g. preemptible nodes VM instances). smart caching saved many lost hours .","code":"\n## Emulate slow function\nslow_square = \n  function(x) {\n    Sys.sleep(2)\n    square(x)\n    }\n# library(memoise) ## Already loaded\n\nmem_square = memoise(slow_square)\nsystem.time({\n  m1 = map_df(1:10, mem_square)\n})\n#>    user  system elapsed \n#>   0.040   0.000  20.402\nsystem.time({\n  m2 = map_df(1:10, mem_square)\n})\n#>    user  system elapsed \n#>   0.002   0.000   0.001\nall.equal(m1, m2)\n#> [1] TRUE\nm2\n#>    value value_squared\n#> 1      1             1\n#> 2      2             4\n#> 3      3             9\n#> 4      4            16\n#> 5      5            25\n#> 6      6            36\n#> 7      7            49\n#> 8      8            64\n#> 9      9            81\n#> 10    10           100\nsystem.time({\n  m3 = map_df(1:15, mem_square)\n})\n#>    user  system elapsed \n#>   0.007   0.000  10.375"},{"path":"funcs-adv.html","id":"caching-across-r-sessions","chapter":"3 Functions: Advanced concepts","heading":"3.4.1 Caching across R sessions","text":"previous paragraph elides important caveat: default memoise() cache valid current R session. can see clearly exploring help documentation function, note internal cache = cache_memory() argument. enable caching persists across sessions — including computer crashes — need specify dedicated cache directory cache = cache_filesystem(PATH). directory can located anywhere system (, indeed, linked cloud storage service) can even multiple cache directories different projects. modest recommendation use .rcache/ naming pattern keep things orderly.example, can specify new, persistent memoise cache location slow_square() function within .rcache sub-directory current project follows.Run new memoised function check saved cached output specified directory.Bottom line: Specify dedicated cache directory complex time-consuming analyses want able access across R sessions.","code":"\n## Specify local cache directory path\ncache_dir = here(\".rcache\")\n\n## Create this local cache directory if it doesn't exist\nif (!dir.exists(cache_dir)) dir.create(cache_dir)\n\n## (Re-)memoise our function with the persistent cache location\nmem_square_persistent = memoise(slow_square, cache = cache_filesystem(cache_dir))\nm4 = map_df(1:7, mem_square_persistent)\n\ncached_files = list.files(cache_dir)\ncached_files\n#> [1] \"01c0e8630e7f14d5\" \"1b4b51ffbcca5468\" \"5083c4a086fa5548\" \"6508857a8ff8ac3b\"\n#> [5] \"c33f179b82a88fea\" \"df6e6c2cd4fd862a\" \"e1779b8cdb7378d7\""},{"path":"funcs-adv.html","id":"verbose-output","chapter":"3 Functions: Advanced concepts","heading":"3.4.2 Verbose output","text":"’s possible (often helpful) add verbose prompts memoised functions. Consider code , folds mem_square_persistent() function two sections:Check load previously cached results. Print results screen.Run memoised function inputs already evaluated.( results cached turn future use.) , print results screen.’s example verbose function action. output probably less impressive knitted R Markdown document, find real-time feedback informative live session. (Try .)Finally, albeit probably unnecessary, can also prove ’ve added three new cases (.e. 8:10) cache directory comparing previously.","code":"\nmem_square_verbose = \n  function(x) {\n    ## 1. Load cached data if already generated\n    if (has_cache(mem_square_persistent)(x)) {\n      cat(\"Loading cached data for x =\", x, \"\\n\")\n      my_data = mem_square_persistent(x)\n      return(my_data)\n    }\n    \n    ## 2. Generate new data if cache not available\n    cat(\"Generating data from scratch for x =\", x, \"...\")\n    my_data = mem_square_persistent(x)\n    cat(\"ok\\n\")\n    \n    return(my_data)\n  }\nsystem.time({\n  m5 = map_df(1:10, mem_square_verbose)\n})\n#> Generating data from scratch for x = 1 ...ok\n#> Generating data from scratch for x = 2 ...ok\n#> Generating data from scratch for x = 3 ...ok\n#> Generating data from scratch for x = 4 ...ok\n#> Generating data from scratch for x = 5 ...ok\n#> Generating data from scratch for x = 6 ...ok\n#> Generating data from scratch for x = 7 ...ok\n#> Generating data from scratch for x = 8 ...ok\n#> Generating data from scratch for x = 9 ...ok\n#> Generating data from scratch for x = 10 ...ok\n#>    user  system elapsed \n#>   0.017   0.004  20.523\nsetdiff(list.files(cache_dir), cached_files)\n#> [1] \"4cecd4ddcc3e39e2\" \"e8f1fd81cf9238e8\" \"f87e79515d7f3630\""},{"path":"funcs-adv.html","id":"further-resources-1","chapter":"3 Functions: Advanced concepts","heading":"3.5 Further resources","text":"RStudio number great debugging resources. recommend Debugging techniques RStudio (recorded talk Amanda Gadrow) Debugging RStudio (Jonathan McPherson).’s less technical specifics, favourite debugging talk Jenny Bryan’s Object type ‘closure’ subsettable. covers (sympathizes ) common debugging frustrations, well general approaches getting help solving problem . typical Jenny fashion, talk funny wise. Watch .Debugging chapter Hadley Wickham’s Advanced R provides thorough treatment. fact, whole book fantastic. ’re looking scale understanding R works underneath hood implement truly high-performance code, can think better reference.","code":""},{"path":"parallel.html","id":"parallel","chapter":"4 Parallel programming","heading":"4 Parallel programming","text":"","code":""},{"path":"parallel.html","id":"software-requirements-2","chapter":"4 Parallel programming","heading":"4.1 Software requirements","text":"","code":""},{"path":"parallel.html","id":"r-packages-2","chapter":"4 Parallel programming","heading":"4.1.1 R packages","text":"New: parallel, future, future.apply, furrr, RhpcBLASctl, tictocAlready used: tidyverse, data.table, pbapply, memoise, , hrbrthemesThe code chunk install (necessary) load packages . Note parallel package bundled together base R installation already system. ’m also going call future::plan() function set resolution “multisession.” Don’t worry means right now — ’ll explain due course — just think convenient way set desired parallel programming behaviour rest document.","code":"\n## Load and install the packages that we'll be using in this chapter\nif (!require(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(tictoc, parallel, pbapply, future, future.apply, tidyverse, \n               hrbrthemes, furrr, RhpcBLASctl, memoise, here)\n#> \n#> The downloaded binary packages are in\n#>  /var/folders/24/8k48jl6d249_n_qfxwsl6xvm0000gn/T//RtmpX6IYWS/downloaded_packages\n#> \n#> The downloaded binary packages are in\n#>  /var/folders/24/8k48jl6d249_n_qfxwsl6xvm0000gn/T//RtmpX6IYWS/downloaded_packages\n#> \n#> The downloaded binary packages are in\n#>  /var/folders/24/8k48jl6d249_n_qfxwsl6xvm0000gn/T//RtmpX6IYWS/downloaded_packages\n## My preferred ggplot2 plotting theme (optional)\ntheme_set(hrbrthemes::theme_ipsum())\n\n## Set future::plan() resolution strategy\nplan(multisession)"},{"path":"parallel.html","id":"prologue","chapter":"4 Parallel programming","heading":"4.2 Prologue","text":"Parallel programming big complex topic, many potential pitfalls. However, software innovations amazing new(ish) packages made much easier safer program parallel.15 mind, ’m going structure chapter back--front. particular, ’m going start motivating examples. primary goal demonstrate ease immediate payoff “going parallel.” convincing facts get technical details abstracted away behind scenes. latter part lecture go parallel programming general terms (.e. R-specific) highlight potential pitfalls aware .Ready? Let’s go.","code":""},{"path":"parallel.html","id":"example-1-slow_square","chapter":"4 Parallel programming","heading":"4.3 Example 1: slow_square","text":"first motivating example going involve slow_square() function saw previous lecture:Let’s iterate function using standard lapply() method ’re familiar now. Note iteration executed serial. ’ll use tictoc package (link) record timing.expected, iteration took 25 seconds run enforced break every sequential iteration (.e. Sys.sleep(2)). hand, means can easily speed things iterating parallel.continuing, ’s worth pointing ability go parallel hinges number CPU cores available us. simplest way obtain information R parallel::detectCores() function:, 3 cores play machine.16 Adjust expectations system accordingly.Okay, back example. ’m going implement parallel iteration using future.apply package (link) — later. Note parameters problem otherwise unchanged.Look : 1× speedup! Even impressively, consider little syntax changed. basically just tell R wanted implement iteration parallel (.e. plan(multisession)) slightly amend lapply() call (.e. future_lapply()).Let’s confirm output .prefer purrr::map() family functions iteration feeling left ; don’t worry. furrr package (link) covered. , syntax parallel functions little changed serial versions. simply tell R want run things parallel plan(multisession) slightly amend map call future_map_dfr().17How easy ? hardly change original code didn’t pay cent extra performance.18 Congratulate already expert parallel programming.","code":"\n## Emulate slow function\nslow_square = \n  function(x = 1) {\n    x_sq = x^2 \n    d = data.frame(value = x, value_squared = x_sq)\n    Sys.sleep(2)\n    return(d)\n    }\n# library(tictoc) ## Already loaded\n\ntic()\nserial_ex = lapply(1:12, slow_square)\ntoc(log = TRUE)\n#> 24.528 sec elapsed\n# future::availableCores() ## Another option\ndetectCores()\n#> [1] 3\n# library(future.apply)  ## Already loaded\n# plan(multisession)     ## Already set above\n\ntic()\nfuture_ex = future_lapply(1:12, slow_square)\ntoc(log = TRUE)\n#> 8.612 sec elapsed\nall.equal(serial_ex, future_ex)\n#> [1] TRUE\n# library(furrr)      ## Already loaded\n# plan(multisession)  ## Already set above\n\ntic()\nfurrr_ex = future_map_dfr(1:12, slow_square)\ntoc()\n#> 8.303 sec elapsed"},{"path":"parallel.html","id":"example-2-bootstrapping","chapter":"4 Parallel programming","heading":"4.4 Example 2: Bootstrapping","text":"second motivating example involve realistic slightly computationally-intensive case: Bootstrapping coefficient values hypothesis testing.19 ’ll also spend bit time talking packages ’re using ’re .Start creating fake dataset (d), “know” relationship x y variables. ’ll specify bootstrapping function (bootstrap()) draw random sample 1,000 observations fake dataset (replacement), fit regression, extract coefficient x variable.","code":"\n## Set seed (for reproducibility)\nset.seed(1234)\n# Set sample size\nn = 1e6\n\n## Generate a large data frame of fake data for a regression\nd = data.frame(x = rnorm(n), e = rnorm(n))\n## Outcome variable. Note that the x coefficient is 2.\nd$y = 3 + 2*d$x + d$e\n\n## Function that draws a sample observations from the fake dataset, then runs a \n## regression and extracts the coefficient value on the x variable.\nbootstrap = \n  function(i) {\n  ## Sample 1,000 rows of our fake dataset\n  dsamp = d[sample.int(1e3, replace = TRUE), ]\n  ## Run a regression on the sampled data, then extract the extract the x\n  ## coefficient (should be around 2).\n  x_coef = lm(y ~ x, dsamp)$coef['x']\n  ## Return value\n  return(data.frame(sim = i, x_coef = x_coef))\n  }"},{"path":"parallel.html","id":"serial-implementation-for-comparison","chapter":"4 Parallel programming","heading":"4.4.1 Serial implementation (for comparison)","text":"Let’s implement bootstrap procedure serial get benchmark comparison. Note ’ll repeat function (.e. simulation) 10,000 times build decent estimate parameter distribution; , , know around 2.took 25 seconds system. huge pain, let’s see can better switching parallel (multicore) implementation. record, though screenshot system monitor, showing one core used serial version.Note: local computer 12 cores, may differ cloud-based virtual machine used build online version book reading.","code":"\nset.seed(123L) ## Optional to ensure that the results are the same\n\n## 10,000-iteration simulation\ntic()\nsim_serial = lapply(1:1e4, bootstrap)\ntoc(log = TRUE)\n#> 17.76 sec elapsed"},{"path":"parallel.html","id":"parallel-implemention-using-the-future-ecosystem","chapter":"4 Parallel programming","heading":"4.4.2 Parallel implemention using the future ecosystem","text":"parallel programming ’ve far built top Henrik Bengtsson’s amazing future package (link). “future” basically flexible way evaluating code output. Among things, allows switch effortlessly evaluating code serial asynchronously (.e. parallel). simply set resolution plan — “sequential,” “multisession,” “cluster,” etc. — let future handle implementation .’s Henrik describing core idea technical terms:programming, future abstraction value may available point future. state future can either unresolved resolved… Exactly futures resolved depends strategy used evaluate . instance, future can resolved using sequential strategy, means resolved current R session. strategies may resolve futures asynchronously, instance, evaluating expressions parallel current machine concurrently compute cluster.’ve tried emphasise, future relatively new scene. certainly first way implement parallel processes R. However, think provides simple unified framework makes preeminent choice. ’s , commands use carry neatly complicated settings involving high-performance computing clusters. ’ll experience first hand get big data section course.’ve probably also noted keep referring “future ecosystem.” future provides framework packages implement parallel versions functions. two ’ll focus :future.apply package (link), also Henrik, andthe furrr package (link), implementation purrr Davis Vaughan.cases, start setting plan resolving future evaluation (: plan(multisession)). call functions — involve minor modifications serial equivalents — let future magic take care everything else.","code":""},{"path":"parallel.html","id":"future.apply","chapter":"4 Parallel programming","heading":"4.4.2.1 future.apply","text":"’s future.apply::future_lapply() parallel implementation. Note ’m adding future.seed=123L option ensure results . strictly necessary, ’s always good idea set random seed simulations sake reproducibility.Remember previous programming chapters lapply returns list (case: list 10,000 single row data frames). bind elements together single, large data frame ’s wanted. example,","code":"\n# library(future.apply)  ## Already loaded\n# plan(multisession)     ## Already set above\n\n## 10,000-iteration simulation\ntic()\nsim_future = future_lapply(1:1e4, bootstrap, future.seed=123L)\ntoc()\n#> 6.63 sec elapsed\n## Bind into single data frame\nsim_future = do.call(\"rbind\", sim_future)\n# sim_future = dplyr::bind_rows(\"rbind\", sim_future)       ## Another option\n# sim_future = data.table::rbindlist(\"rbind\", sim_future)  ## Another option\n\nhead(sim_future)\n#>    sim   x_coef\n#> x    1 2.038696\n#> x1   2 1.988938\n#> x2   3 1.970760\n#> x3   4 1.968304\n#> x4   5 2.011383\n#> x5   6 2.001061"},{"path":"parallel.html","id":"furrr","chapter":"4 Parallel programming","heading":"4.4.2.2 furrr","text":"’s furrr::future_map_dfr() implementation. Similar , note ’m adding .options=future_options(seed=123L) option ensure output exactly .","code":"\n# library(furrr)      ## Already loaded\n# plan(multisession)  ## Already set above\n\n## 10,000-iteration simulation\ntic()\nsim_furrr = future_map_dfr(1:1e4, bootstrap, .options = furrr_options(seed=123L))\ntoc()\n#> 6.498 sec elapsed\n\nhead(sim_furrr)\n#>       sim   x_coef\n#> x...1   1 2.038696\n#> x...2   2 1.988938\n#> x...3   3 1.970760\n#> x...4   4 1.968304\n#> x...5   5 2.011383\n#> x...6   6 2.001061"},{"path":"parallel.html","id":"results","chapter":"4 Parallel programming","heading":"4.4.3 Results","text":"expected, dramatically cut total computation time going parallel. Depending system, may note parallel improvements example didn’t scale linearly number cores. reason overhead running parallel implementations — topic cover depth toward bottom document. , record, screenshot showing cores now used parallel implementations.Note: local computer 12 cores, may differ cloud-based virtual machine used build online version book reading.wasn’t exactly hard work, think deserve see results bootstrapping exercise nice plot form. ’ll use sim_furrr results data frame , although doesn’t matter since ’re thanks random seed. can see, estimated coefficient values tightly clustered around simulated mean 2.","code":"\nsim_furrr %>%\n  ggplot(aes(x_coef)) +\n  geom_density(col=NA, fill=\"gray25\", alpha=0.3) +\n  geom_vline(xintercept=2, col=\"red\") +\n  labs(\n    title = \"Bootstrapping example\",\n    x=\"Coefficient values\", y=\"Density\",\n    caption = \"Notes: Density based on 10,000 draws with sample size of 10,000 each.\"\n    )"},{"path":"parallel.html","id":"other-parallel-options","chapter":"4 Parallel programming","heading":"4.4.4 Other parallel options","text":"Futures game town parallel programming R. example, ’m going talk base R mclapply function . However, one particular option want mention briefly pbapply package (link). saw first programming lecture, package provides lightweight wrapper *apply functions adds progress bar. However, package also adds convenient option multicore implementation. basically just add cl=CORES call. doesn’t rely futures, pbapply also takes care OS-specific overhead . See interesting discussion ’s happening behind scenes.need run next chunk interactively see progress bar.Aside: subject progress bars, check progressr package (link) unified framework works kinds functions ()syncronous backends.","code":"\nset.seed(123) ## Optional to ensure results are exactly the same.\n\n# library(pbapply) ## Already loaded\n\n## 10,000-iteration simulation\ntic()\nsim_pblapply = pblapply(1:1e4, bootstrap, cl = parallel::detectCores())\ntoc()\n#> 6.495 sec elapsed"},{"path":"parallel.html","id":"general-parallel-programming-topics","chapter":"4 Parallel programming","heading":"4.5 General parallel programming topics","text":"Motivating examples way, let’s take look underneath hood. want emphasise section “good know” “need know.” Even take nothing else away rest lecture, already well placed begin implementing parallel functions much larger scale.yet… don’t need know next section order program parallel R, getting solid grasp basics valuable. give better understanding parallel programming works general help appreciate much future co. behind scenes . also help understand code runs faster systems others, avoid common pitfalls.","code":""},{"path":"parallel.html","id":"terminology","chapter":"4 Parallel programming","heading":"4.5.1 Terminology","text":"’ll start clearing terminology.Socket: physical connection computer houses processor. work home computers — even high-end ones — one socket , thus, one processor. However, can multiple cores. Speaking …Core: part processor actually performs computation. Back day, processors limited single core. However, modern processors now house multiple cores. cores can perform entirely separate independent computational processes.Process: single instance running task program (R, Dropbox, etc). single core can run one process time. However, may give appearance efficiently scheduling . Speaking …Thread: component subset process can, inter alia, share memory resources threads. ’ll return idea applies hyperthreading paragraphs.Cluster: collection objects capable hosting cores. range single socket (home computer) array servers (high-performance computing network).may wondering much-referenced CPU (.e. central processing unit) fits . Truth told, meaning CPU evolved advent new technology like multicore processors. purposes lecture use following definition:\\[\\text{. CPUs} = \\text{. sockets} \\times \\text{. physcial cores} \\times \\text{. threads per core}\\]nothing else, consistent way Linux system records information CPU architecture via lscpu shell command:Note headline “CPU(s)” number got running parallel::detectCores() earlier (.e. 3).","code":"> ## Only works on Linux\n+ lscpu | grep -E '^Thread|^Core|^Socket|^CPU\\('\n#> bash: line 1: lscpu: command not found"},{"path":"parallel.html","id":"a-bit-more-about-logical-cores-and-hyperthreading","chapter":"4 Parallel programming","heading":"4.5.2 A bit more about logical cores and hyperthreading","text":"Logical cores extend emulate ability physical cores perform additional tasks. famous example Intel’s hyperthreading technology, allows single core switch rapidly two different tasks. mimics appearance performance (albeit lesser extent) extra physical core. may find YouTube video helpful understanding difference depth, including nice analogy involving airport security lines.Taking step back, don’t worry much difference physical logical (hyperthreaded) cores purpose lecture. R doesn’t care whether run function physical core logical one. work equally well. (Okay, latter little slower.) Still, interested determining number physical cores versus logical cores system, several ways R. example, can use RhpcBLASctl package (link).","code":"\n# library(RhpcBLASctl) ## Already loaded\n\nget_num_procs() ## No. of all cores (including logical/hyperthreaded)\n#> [1] 3\nget_num_cores() ## No. of physical cores only\n#> [1] 3"},{"path":"parallel.html","id":"forking-vs-sockets","chapter":"4 Parallel programming","heading":"4.5.3 Forking vs Sockets","text":"keep saying, ’s now incredibly easy run parallel programs R. truth actually easy long time, implementation used vary operating system. particular, simple parallel implementations worked perfectly well Linux Mac didn’t work Windows (required lot overhead). example, take look help documentation parallel::mclapply() function, around since 2011. , see warning mclapply() “relies forking hence available Windows”.Now, clearly didn’t encounter OS-specific problems ran parallel versions motivating examples . code worked everyone, including anyone using Windows. Loud booing. happening behind scenes future packages automatically handled complications us. parallel functions executed way optimized person’s OS R environment.“forking” matter OS using anyway? good questions relate method parallelization (.e. type cluster) system supports. short version basically two ways code can parallelized:Forking works cloning entire R environment separate core. includes data, loaded packages, functions, objects current session. efficient don’t worry reproducing “master” environment “worker” node. Everything already linked, means aren’t duplicating objects memory. However, forking supported Windows can also cause problems IDE GUI like RStudio.20Parallel sockets (aka “PSOCKs”) work launching new R session core. means master environment copied instantiated separately parallel node. requires greater overhead causes everything run slower, since objects duplicated across core. Technically, PSOCK works establishing network (e.g. connected remote cluster), everything self-contained computer. approach can implemented every system, including Windows, doesn’t create problems IDEs like RStudio.’ve summarised differences two approaches table .general rule thumb PSOCKs safer universal forking. makes good default, even come potential performance/memory penalty. , indeed, exactly selecting plan(multisession) resolution strategy. , now know choice came .time, however, recommend consider forking available (.e. ’re Linux Mac) want maximize performance. cases, solution requires two simple tweaks:Change resolution plan plan(multicore), andRun R script terminal using, say, $ Rscript -e 'rmarkdown::render(\"mydoc.Rmd\", \"\")' $ Rscript myfile.R.’s simple illustration, using setup Example 1 earlier.see invoking forked parallel backend (.e. plan(multicore)) indeed faster PSOCK equivalent (.e. plan(multisession)). remember: Caveat emptor.forks vs PSOCKS, take look relevant section future README.","code":"\nplan(multicore) ## NB: Only works on Unix!\n\ntic()\nfuture_ex_mc = future_lapply(1:12, slow_square)\ntoc(log = TRUE)\n#> 8.367 sec elapsed"},{"path":"parallel.html","id":"explicit-vs-implicit-parallelization","chapter":"4 Parallel programming","heading":"4.6 Explicit vs implicit parallelization","text":"Thus far concerned explicit parallelization. , explicitly told R run particular set commands parallel. another form implicit parallelization equally important aware . case, certain low-level functions operations automatically run parallel regardless whether “told” R . Implicit parallelization can make big difference performance, default behaviour R. enabled first (example, package ’re using). Moreover, combining explicit implicit parallelization can cause problems don’t take certain precautions. Let’s take look implicit parallelization enters fray.","code":""},{"path":"parallel.html","id":"blaslapack","chapter":"4 Parallel programming","heading":"4.6.1 BLAS/LAPACK","text":"ever wonder R programming languages perform calculations? example, R actually things like vector addition, scalar matrix multiplication? answer BLAS (Basic Linear Algebra Suprograms). BLAS collection low-level routines provide standard building blocks performing basic vector matrix operations. routines incorporated related libraries like LAPACK (Linear Algebra Package), provide routines solving systems linear equations linear least squares, calculating eigenvalues, etc. words, BLAS LAPACK provide linear algebra framework supports virtually statistical computational programmingR ships BLAS/LAPACK libraries default. libraries place premium stability (e.g. common user experience across operating systems). default works well enough, can get significant speedups switching optimized libraries Intel Math Kernel Library (MKL) OpenBLAS. Among things, optimized BLAS libraries support multi-threading. now using available computer power , say, solve matrix.can use sessionInfo() command see BLAS/LAPACK library using.","code":""},{"path":"parallel.html","id":"beware-resource-competition","chapter":"4 Parallel programming","heading":"4.6.2 Beware resource competition","text":"sounds great — certainly recommend taking look MKL OpenBLAS — potential downside. particular, risk competing computational resources (.e. memory) mix explicit implicit parallel calls. instance, run explicit multicore functions within R system configured optimized BLAS. Dirk Eddelbuettel succinctly puts Stack Overflow thread:one situation want avoid: (1) spreading task N cores (2) core work task using something like OpenBLAS MKL cores. now N N contention: N task wants farm linear algebra work N cores.Now, want emphasise conflict rarely matters experience. use optimized BLAS libraries run explicit parallel calls time R scripts. Despite , hardly ever run problem. Moreover, slowdowns occurred, ’ve found effect relatively modest.21 Still, read cases effect can quite dramatic (e.g. ) wanted aware .Luckily, ’s also easy relatively costless solution: Simply turn BLAS multi-threading. turns negligible impact performance, since gains optimized BLAS actually coming improved math vectorisation, multi-threading. (See post detailed discussion.) can turn BLAS multi-threading current R session via RhpcBLASctl::blas_set_num_threads() function. example, sometimes include following line top R script:Since effect current R session, BLAS multithreading restored restart R.22 can turn BLAS multithreading default mode setting appropriate environment variable. ’ll revisit chapter(s) Google Compute Engine.","code":"\n# blas_get_num_procs() ## If you want to find the existing number of BLAS threads\nRhpcBLASctl::blas_set_num_threads(1) ## Set BLAS threads to 1 (i.e. turn off multithreading)"},{"path":"parallel.html","id":"library-source-code","chapter":"4 Parallel programming","heading":"4.6.3 Library source code","text":"briefly, want point implicit parallelization automatically invoked many external libraries use R. good news package developers normally take pains avoid potential resource competition. instance, consider message data.table greets us load time.follow suggestion look ?getDTthreads help documentation, ’ll find informative (reassuring) discussion approach :data.table automatically switches single threaded mode upon fork (mechanism used parallel::mclapply foreach package). Otherwise, nested parallelism likely overload CPUs result much slower execution. data.table becomes parallel internally, expect explicit user parallelism needed less often…final point topic, riffing quoted text, packages like data.table implement parallel operations source-code level, .e. C(++) compiled languages. likely efficient equivalent explicit parallel calls might make. ’s can’t combine, say, future data.table (often). know trying better latter’s default operations may fool’s errand.","code":"\nlibrary(data.table, warn.conflicts = FALSE)#> data.table 1.14.0 using 6 threads (see ?getDTthreads).  Latest news: r-datatable.com"},{"path":"parallel.html","id":"miscellaneous","chapter":"4 Parallel programming","heading":"4.7 Miscellaneous","text":"","code":""},{"path":"parallel.html","id":"when-should-i-go-parallel","chapter":"4 Parallel programming","heading":"4.7.1 When should I go parallel?","text":"short answer want invoke multicore option whenever faced -called “embarrassingly parallel” problem. can click link longer description, key idea computational problems easy break smaller chunks. likely case potential code chunks independent need communicate way. Classic examples include bootstrapping (since regression resampling iteration drawn independently) Markov chain Monte Carlo (.e. MCMC).said , limitations gains can parallelization. obviously, computational overhead associated splitting problem, tracking individual nodes, bringing everything back single result. can regarded issue largely affecting shorter smaller computations. words, overhead component problem tends diminish relative size overall computation time increases.opposite end spectrum, Amdahl’s law (generalised Gustafson’s law). formalises intuitive idea diminishing returns parallelization, depending proportion code can run parallel. case point Bayesian MCMC routines, typically include fixed “burn-” period regardless many parallel chains run parallel.","code":""},{"path":"parallel.html","id":"how-many-cores-should-i-use","chapter":"4 Parallel programming","heading":"4.7.2 How many cores should I use?","text":"look question online, ’ll find people recommend using detectCores()-1. advice stems idea probably want reserve one core tasks, running web browser word processor. don’t disagree, typically use available cores parallel computations. one thing, heavy computational work cloud (.e. server virtual machine). keeping computational power reserve doesn’t make sense. Second, working locally, ’ve gotten habit closing applications parallel function running. mileage may vary, though. (remember possible diminishing returns brought Amdahl’s law). FWIW, calling plan(multisession) plan(multicore) automatically default using cores. can change running, say, plan(multisession(workers = detectCores()-1)).","code":""},{"path":"parallel.html","id":"fault-tolerance-error-catching-caching-etc.","chapter":"4 Parallel programming","heading":"4.7.3 Fault tolerance (error catching, caching, etc.)","text":"experience, worst thing parallel computation sensitive failure one nodes. especially frustrating example tendency parallel functions ignore/hide critical errors end supposed return output. (“Oh, encountered critical error several hours ago, just decided continue fun anyway? Thanks!”) Luckily, defensive programming tools practiced previous lecture — catching user errors caching intermediate results — carry perfectly parallel equivalents. Just make sure use persistent cache.Challenge: Prove running parallel version cached iteration practiced last time. Specifically, recreate mem_square_verbose() function, turn relies mem_square_persistent() function.23 able run future_map_dfr(1:10, mem_square_verbose) automatically return previously cached results. , try future_map_dfr(1:24, mem_square_verbose) see happens.","code":""},{"path":"parallel.html","id":"random-number-generation","chapter":"4 Parallel programming","heading":"4.7.4 Random number generation","text":"Random number generation (RNG) can become problematic parallel computations (whether trying ensure different RNG across processes). R various safeguards future automatically handles RNG via future.seed argument. saw explicit example Example 2 .","code":""},{"path":"parallel.html","id":"parallel-regression","chapter":"4 Parallel programming","heading":"4.7.5 Parallel regression","text":"number regression packages R optimized run parallel. example, superb fixest package (link) saw lecture regression analysis automatically invoke multicore capabilities fitting high dimensional fixed effects models. many Bayesian packages R also capable — , indeed, expected — fit regression models running MCMC chains parallel. example, RStan (link). Finally, may interested partools package (link), provides convenient aliases running variety statistical models algorithms parallel.","code":""},{"path":"parallel.html","id":"cpus-vs-gpus","chapter":"4 Parallel programming","heading":"4.7.6 CPUs vs GPUs","text":"Graphical Processing Units, GPUs, specialised chipsets originally built perform heavy lifting associated rendering graphics. ’s important realise computers GPUs. laptops come -called integrated graphics, basically means processor performing regular graphic-rendering tasks. However, gaming high-end laptops (many desktop computers) include dedicated GPU card. example, Dell Precision 5530 ’m writing lecture notes hybrid graphics setup two cards: 1) integrated Intel GPU (UHD 630) 2) discrete NVIDIA Quadro P2000.telling ? Well, turns GPUs also excel non-graphic computation tasks. processing power needed perform millions parallel calculations rendering 3-D games architectural software, can put use scientific problems. exactly discovered involves interesting backstory supercomputers built Playstations. (Google .) short version modern GPUs comprise thousands cores can run parallel. , colleague David Evans memorably described : “GPUs basically just really, really good linear algebra.”Still, ’s much want say GPUs now. Installing maintaining working GPU setup scientific purposes much complex task. (, frankly, overkill vast majority econometric data science needs.) may revisit topic get machine learning section course weeks.24 Thus, general concepts carry , everything ’ve covered chapter limited CPUs.","code":""},{"path":"parallel.html","id":"monitoring-multicore-performance","chapter":"4 Parallel programming","heading":"4.7.7 Monitoring multicore performance","text":"Bash-compatible shells come built-top command, provides real-time view running processes resource consumption. (Pro-tip: Hit “1” view processes across individual cores “q” quit.) enhanced alternative really like use time htop, available Linux Mac. (Windows users can install htop WSL covered way back shell lecture.). ’s entirely whether want install . operating system almost certainly provides built-tools monitoring processes resource usage (e.g. System Monitor). However, wanted flag htop get big data section course. ’ll connecting remote Linux servers point shell-based (.e. non-GUI) process monitor prove handy tracking resource use.","code":""},{"path":"parallel.html","id":"further-resources-2","chapter":"4 Parallel programming","heading":"4.8 Further resources","text":"Dirk Eddelbuettel provides authoritative reference topic review paper, Parallel Computing R: Brief Review (pre-print).Beyond Dirk’s article, ’d argue starting point reading future vignettes (one, two, three, four, five). ’s lot , feel free pick choose.Similarly, furrr package vignette informative (concise).parallel package vignette provides good overview, purpose, parallel programming general. Particular attention paid steps needed ensure stable R environment (e.g. across operating systems).Finally, number resources online detail older parallel programming methods R (foreach, mclapply, parLapply snow, etc.). methods clearly superseded future package ecosystem mind, still lot valuable information gleaned understanding . Two favourite resources regard : -go parallel R (Max Gordon) Beyond Single-Core R (Jonathan Dursi).","code":""},{"path":"spatial-analysis.html","id":"spatial-analysis","chapter":"5 Spatial analysis","heading":"5 Spatial analysis","text":"","code":""},{"path":"spatial-analysis.html","id":"requirements","chapter":"5 Spatial analysis","heading":"5.1 Requirements","text":"","code":""},{"path":"spatial-analysis.html","id":"external-libraries-requirements-vary-by-os","chapter":"5 Spatial analysis","heading":"5.1.1 External libraries (requirements vary by OS)","text":"’re going spatial analysis plotting today R. Behind scenes, R provides bindings powerful open-source GIS libraries. include Geospatial Data Abstraction Library (GDAL) Interface Geometry Engine Open Source (GEOS) API suite, well access projection transformation operations PROJ library. needn’t worry , fact may need install external libraries first. requirements vary OS:Linux: Requirements vary distribution. See .Mac: fine proceed directly R packages installation . unlikely exception ’ve configured R install packages source; case see .Windows: Mac, good go unless ’re installing source. case, see .","code":""},{"path":"spatial-analysis.html","id":"r-packages-3","chapter":"5 Spatial analysis","heading":"5.1.2 R packages","text":"New: sf, rgeos, lwgeom, maps, mapdata, spData, tigris, tidycensus, leaflet, mapview, tmap, tmaptoolsAlready used: tidyverse, data.table, hrbrthemesTruth told, need handful libraries 95% spatial work ’re likely encounter. R’s spatial ecosystem support extremely rich, ’ll try walk number specific use-cases lecture. Run following code chunk install (necessary) load everything.","code":"\n## Load and install the packages that we'll be using today\nif (!require(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(sf, rgeos, tidyverse, data.table, hrbrthemes, lwgeom, rnaturalearth, maps, mapdata, spData, tigris, tidycensus, leaflet, mapview, tmap, tmaptools)\n## My preferred ggplot2 plotting theme (optional)\ntheme_set(hrbrthemes::theme_ipsum())"},{"path":"spatial-analysis.html","id":"census-api-key","chapter":"5 Spatial analysis","heading":"5.1.3 Census API key","text":"Finally, ’ll accessing data US Census Bureau tidycensus package. require Census API key, can request . ’s done, can set using tidycensus::census_api_key() function. recommend using “install = TRUE” option save key future usage. See function’s help file information.","code":"\ntidycensus::census_api_key(\"PLACE_YOUR_API_KEY_HERE\", install = TRUE)"},{"path":"spatial-analysis.html","id":"introduction-crs-and-map-projections","chapter":"5 Spatial analysis","heading":"5.2 Introduction: CRS and map projections","text":"Student presentation time.’re reading fact, recommend two helpful resources. short version spatial data, like coordinate-based systems, make sense relative fixed point. fixed point Coordinate Reference Systems, CRS, trying set. R, can define CRS one two ways:EPSG code (e.g. 3857), orEPSG code (e.g. 3857), orPROJ string (e.g. \"+proj=merc\").PROJ string (e.g. \"+proj=merc\").’ll see examples implementations lecture. moment, however, just know equally valid ways specifying CRS R (albeit different strengths weaknesses). can search many different CRS definitions .Aside: important updates happening world CRS geospatial software, percolate R spatial ecosystem. Thanks hard work various R package developers, behind--scenes changes unlikely affect way interact spatial data R. worth understanding plan make geospatial work core component research. .Similarly, whenever try plot (part ) earth map, ’re effectively trying project 3-D object onto 2-D surface. necessarily create kind distortion. Different types map projections limit distortions parts world expense others. example, consider badly standard (infamous) Mercator projection distorts high latitudes global map (source):Bottom line: always aim choose projection best represents specific area study. ’ll also show can “re-orient” projection specific latitude longitude using PROJ syntax. first ’m obliged share XKCD summary. (favour click link.)","code":""},{"path":"spatial-analysis.html","id":"simple-features-and-the-sf-package","chapter":"5 Spatial analysis","heading":"5.3 Simple Features and the sf package","text":"R long provided excellent support spatial analysis plotting (primarily sp, rgdal, rgeos, raster packages). However, recently, complex structure spatial data necessitated set equally complex spatial objects R. won’t go details, spatial object (say, SpatialPolygonsDataFrame) typically comprised several “layers” — much like list — layer containing variety “slots.” approach (still ) work perfectly well, convoluted structure provided barriers entry newcomers. also made difficult incorporate spatial data tidyverse ecosystem ’re familiar . Luckily, changed thanks advent sf package (link).“sf” stands simple features, simple (ahem) standard representing spatial geometries real-world objects computer.25 objects — .e. “features” — include tree, building, country’s border, entire globe. point characterised common set rules, defining everything stored computer geometrical operations can applied . greater importance purposes, however, fact sf represents features R data frames. means data wrangling skills previous lectures can applied spatial data; say nothing specialized spatial functions ’ll cover next.","code":""},{"path":"spatial-analysis.html","id":"reading-in-spatial-data","chapter":"5 Spatial analysis","heading":"5.3.1 Reading in spatial data","text":"Somewhat confusingly, functions sf package start prefix st_. stands spatial temporal basic command package easy enough remember ’re probably looking st_SOMETHING().26Let’s demonstrate reading North Carolina counties shapefile comes bundled sf. might guessed, ’re going use st_read() command sf package handle heavy lifting behind scenes.","code":"\n# library(sf) ## Already loaded\n\n## Location of our shapefile (here: bundled together with the sf package)\nfile_loc = system.file(\"shape/nc.shp\", package=\"sf\")\n\n## Read the shapefile into R\nnc = st_read(file_loc, quiet = TRUE)"},{"path":"spatial-analysis.html","id":"simple-features-as-data-frames","chapter":"5 Spatial analysis","heading":"5.3.2 Simple Features as data frames","text":"Let’s print nc object just created take look structure.Now can see explicit data frame structure talking earlier. object familiar tibble-style output ’re used (e.g. prints first 10 rows data). However, also additional information header, like description geometry type (“MULTIPOLYGON”) CRS (e.g. EPSG ID 4267). One thing want note particular geometry column right end data frame. geometry column sf package achieves much magic: stores geometries row element list column.27 Since really care key feature attributes — county name, FIPS code, population size, etc. — can focus instead getting bogged hundreds (thousands even millions) coordinate points. turn, means favourite tidyverse operations syntax (including pipe operator %>%) can applied spatial data. Let’s review examples, starting plotting.","code":"\nnc\n#> Simple feature collection with 100 features and 14 fields\n#> geometry type:  MULTIPOLYGON\n#> dimension:      XY\n#> bbox:           xmin: -84.32385 ymin: 33.88199 xmax: -75.45698 ymax: 36.58965\n#> geographic CRS: NAD27\n#> First 10 features:\n#>     AREA PERIMETER CNTY_ CNTY_ID        NAME  FIPS FIPSNO CRESS_ID BIR74 SID74\n#> 1  0.114     1.442  1825    1825        Ashe 37009  37009        5  1091     1\n#> 2  0.061     1.231  1827    1827   Alleghany 37005  37005        3   487     0\n#> 3  0.143     1.630  1828    1828       Surry 37171  37171       86  3188     5\n#> 4  0.070     2.968  1831    1831   Currituck 37053  37053       27   508     1\n#> 5  0.153     2.206  1832    1832 Northampton 37131  37131       66  1421     9\n#> 6  0.097     1.670  1833    1833    Hertford 37091  37091       46  1452     7\n#> 7  0.062     1.547  1834    1834      Camden 37029  37029       15   286     0\n#> 8  0.091     1.284  1835    1835       Gates 37073  37073       37   420     0\n#> 9  0.118     1.421  1836    1836      Warren 37185  37185       93   968     4\n#> 10 0.124     1.428  1837    1837      Stokes 37169  37169       85  1612     1\n#>    NWBIR74 BIR79 SID79 NWBIR79                       geometry\n#> 1       10  1364     0      19 MULTIPOLYGON (((-81.47276 3...\n#> 2       10   542     3      12 MULTIPOLYGON (((-81.23989 3...\n#> 3      208  3616     6     260 MULTIPOLYGON (((-80.45634 3...\n#> 4      123   830     2     145 MULTIPOLYGON (((-76.00897 3...\n#> 5     1066  1606     3    1197 MULTIPOLYGON (((-77.21767 3...\n#> 6      954  1838     5    1237 MULTIPOLYGON (((-76.74506 3...\n#> 7      115   350     2     139 MULTIPOLYGON (((-76.00897 3...\n#> 8      254   594     2     371 MULTIPOLYGON (((-76.56251 3...\n#> 9      748  1190     2     844 MULTIPOLYGON (((-78.30876 3...\n#> 10     160  2038     5     176 MULTIPOLYGON (((-80.02567 3..."},{"path":"spatial-analysis.html","id":"plotting-and-projection-with-ggplot2","chapter":"5 Spatial analysis","heading":"5.3.3 Plotting and projection with ggplot2","text":"Plotting sf objects incredibly easy thanks package’s integration base R plot() ggplot2. ’m going focus latter , feel free experiment.28 key geom remember geom_sf(). example:reproject sf object different CRS, can use sf::st_transform()., can specify common projection directly ggplot call using coord_sf(). often convenient approach combining multiple sf data frames plot.Note used PROJ string define CRS reprojection . easily use EPSG code instead. example, ’s NC state plane projection.","code":"\n# library(tidyverse) ## Already loaded\n\nnc_plot = \n  ggplot(nc) +\n  geom_sf(aes(fill = AREA), alpha=0.8, col=\"white\") +\n  scale_fill_viridis_c(name = \"Area\") +\n  ggtitle(\"Counties of North Carolina\")\n\nnc_plot\nnc %>%\n  st_transform(crs = \"+proj=moll\") %>% ## Reprojecting to a Mollweide CRS\n  head(2) ## Saving vertical space\n#> Simple feature collection with 2 features and 14 fields\n#> geometry type:  MULTIPOLYGON\n#> dimension:      XY\n#> bbox:           xmin: -7160488 ymin: 4364312 xmax: -7077217 ymax: 4404766\n#> CRS:            +proj=moll\n#>    AREA PERIMETER CNTY_ CNTY_ID      NAME  FIPS FIPSNO CRESS_ID BIR74 SID74\n#> 1 0.114     1.442  1825    1825      Ashe 37009  37009        5  1091     1\n#> 2 0.061     1.231  1827    1827 Alleghany 37005  37005        3   487     0\n#>   NWBIR74 BIR79 SID79 NWBIR79                       geometry\n#> 1      10  1364     0      19 MULTIPOLYGON (((-7145982 43...\n#> 2      10   542     3      12 MULTIPOLYGON (((-7118092 43...\nnc_plot +\n  coord_sf(crs = \"+proj=moll\") +\n  labs(subtitle = \"Mollweide projection\") \nnc_plot +\n  coord_sf(crs = 32119) +\n  labs(subtitle = \"NC state plane\") "},{"path":"spatial-analysis.html","id":"data-wrangling-with-dplyr-and-tidyr","chapter":"5 Spatial analysis","heading":"5.3.4 Data wrangling with dplyr and tidyr","text":"keep saying, tidyverse approach data wrangling carries smoothly sf objects. example, standard dplyr verbs like filter(), mutate() select() work:can also perform group_by() summarise() operations per normal (see nice example). Furthermore, dplyr family join functions also work, can especially handy combining different datasets (say) FIPS code attribute. However, presumes one objects specialized geometry column. words, works joining sf object normal data frame. cases want join two sf objects based geometries, ’s specialized st_join() function. provide example latter operation section geometric operations ., just show ’ve got bases covered, can also implement favourite tidyr verbs. example, can tidyr::gather() data long format, useful facetted plotting.29 demonstrate using “BIR74” “BIR79” columns (.e. number births county 1974 1979, respectively).","code":"\nnc %>%\n  filter(NAME %in% c(\"Camden\", \"Durham\", \"Northampton\")) %>%\n  mutate(AREA_1000 = AREA*1000) %>%\n  select(NAME, contains(\"AREA\"), everything())\n#> Simple feature collection with 3 features and 15 fields\n#> geometry type:  MULTIPOLYGON\n#> dimension:      XY\n#> bbox:           xmin: -79.01814 ymin: 35.85786 xmax: -75.95718 ymax: 36.55629\n#> geographic CRS: NAD27\n#>          NAME  AREA AREA_1000 PERIMETER CNTY_ CNTY_ID  FIPS FIPSNO CRESS_ID\n#> 1 Northampton 0.153       153     2.206  1832    1832 37131  37131       66\n#> 2      Camden 0.062        62     1.547  1834    1834 37029  37029       15\n#> 3      Durham 0.077        77     1.271  1908    1908 37063  37063       32\n#>   BIR74 SID74 NWBIR74 BIR79 SID79 NWBIR79                       geometry\n#> 1  1421     9    1066  1606     3    1197 MULTIPOLYGON (((-77.21767 3...\n#> 2   286     0     115   350     2     139 MULTIPOLYGON (((-76.00897 3...\n#> 3  7970    16    3732 10432    22    4948 MULTIPOLYGON (((-79.01814 3...\nnc %>% \n  select(county = NAME, BIR74, BIR79, -geometry) %>% \n  gather(year, births, BIR74, BIR79) %>% \n  mutate(year = gsub(\"BIR\", \"19\", year)) %>%\n  ggplot() +\n  geom_sf(aes(fill = births), alpha=0.8, col=\"white\") +\n  scale_fill_viridis_c(name = \"Births\", labels = scales::comma) +\n  facet_wrap(~year, ncol = 1) +\n  labs(title = \"Births by North Carolina county\") "},{"path":"spatial-analysis.html","id":"geometric","chapter":"5 Spatial analysis","heading":"5.3.5 Specialized geometric operations","text":"Alongside tidyverse functionality, sf package comes full suite geometrical operations. take look third sf vignette Geocomputation R book get complete overview. However, examples get started:","code":""},{"path":"spatial-analysis.html","id":"unary-operations","chapter":"5 Spatial analysis","heading":"5.3.5.1 Unary operations","text":"-called unary operations applied single object. instance, can “melt” sub-elements sf object (e.g. counties) larger elements (e.g. states) using sf::st_union():, can get st_area(), st_centroid(), st_boundary(), st_buffer(), etc. object using appropriate command. example::","code":"\nnc %>% \n  st_union() %>% \n  ggplot() +\n  geom_sf(fill=NA, col=\"black\") +\n  labs(title = \"Outline of North Carolina\") \n#> although coordinates are longitude/latitude, st_union assumes that they are planar\nnc %>% st_area() %>% head(5) ## Only show the area of the first five counties to save space.\n#> Units: [m^2]\n#> [1] 1137388604  611077263 1423489919  694546292 1520740530\nnc_centroid = st_centroid(nc)\n\nggplot(nc) +\n  geom_sf(fill = \"black\", alpha = 0.8, col = \"white\") +\n  geom_sf(data = nc_centroid, col = \"red\") + ## Notice how easy it is to combine different sf objects\n  labs(\n    title = \"Counties of North Carolina\",\n    subtitle = \"Centroids in red\"\n    )"},{"path":"spatial-analysis.html","id":"binary-operations","chapter":"5 Spatial analysis","heading":"5.3.5.2 Binary operations","text":"Another set -called binary operations can applied multiple objects. , can get things like distance two spatial objects using sf::st_distance(). example, ’m going get distance Ashe county Brunswich county, well . latter just silly addition show can easily make multiple pairwise comparisons, even distance one element another zero.","code":"\nashe_brunswick = nc %>% filter(NAME %in% c(\"Ashe\", \"Brunswick\"))\nbrunswick = nc %>% filter(NAME %in% c(\"Brunswick\"))\n\n## Use \"by_element = TRUE\" to give a vector instead of the default pairwise matrix\nab_dist = st_distance(ashe_brunswick, brunswick, by_element = TRUE)\n# Units: [m]\n# [1] 347930.7      0.0\n\n## We can use the `units` package (already installed as sf dependency) to convert to kilometres \nab_dist = ab_dist %>% units::set_units(km) %>% round()\n# Units: [km]\n# [1] 348   0\n\nggplot(nc) +\n  geom_sf(fill = \"black\", alpha = 0.8, col = \"white\") +\n  geom_sf(data = nc %>% filter(NAME %in% c(\"Ashe\", \"Brunswick\")), aes(fill = NAME), col = \"white\") +  \n  labs(\n    title = \"Calculating distances\",\n    subtitle = paste0(\"The distance between Ashe and Brunswick is \", ab_dist[1], \" km\")\n    ) +\n  theme(legend.title = element_blank())"},{"path":"spatial-analysis.html","id":"binary-logical-operations","chapter":"5 Spatial analysis","heading":"5.3.5.3 Binary logical operations","text":"sub-genre binary geometric operations falls category logic rules — typically characterising way geometries relate space. (overlap, etc.)example, can calculate intersection different spatial objects using sf::st_intersection(). next example, ’m going use two new spatial objects: 1) regional map France maps package 2) part Seine river network (including Marne Yonne tributaries) spData package. Don’t worry much process used loading datasets; ’ll cover depth shortly. moment, just focus idea want see adminstrative regions intersected river network. Start plotting data get visual sense overlap:Now let’s limit intersected regions:Note st_intersection() preserves exact points overlap. , exact path rivers follow within regions. can see explicitly map form:instead wanted plot subsample intersected provinces (.e. keeping full geometries), couple options. filter france object matching region IDs france_intersected object. However, direct option use sf::st_join() function matches objects based overlapping (.e. intersecting) geometries:’s much sf functionality can show today. remaining part lecture cover additional mapping considerations bonus spatial R “swag.” However, ’ll try slip sf-specific operations along way.","code":"\n## Get the data\nfrance = st_as_sf(map('france', plot = FALSE, fill = TRUE))\ndata(\"seine\", package = \"spData\")\n\n## Make sure they have the same projection\nseine = st_transform(seine, crs = st_crs(france))\n\nggplot() + \n  geom_sf(data = france, alpha = 0.8, fill = \"black\", col = \"gray50\") + \n  geom_sf(data = seine, col = \"#05E9FF\", lwd = 1) + \n  labs(\n    title = \"Administrative regions of France\",\n    subtitle = \"Also showing the Seine, Marne and Yonne rivers\"\n    )\nseine = st_transform(seine, crs = st_crs(france))\nfrance_intersected = st_intersection(france, seine)\nfrance_intersected\n#> Simple feature collection with 22 features and 2 fields\n#> geometry type:  GEOMETRY\n#> dimension:      XY\n#> bbox:           xmin: 0.4931747 ymin: 47.04007 xmax: 5.407725 ymax: 49.52717\n#> geographic CRS: WGS 84\n#> First 10 features:\n#>                     ID  name                           geom\n#> 6                Aisne Marne LINESTRING (3.608053 49.089...\n#> 14               Marne Marne LINESTRING (4.872966 48.637...\n#> 17      Seine-et-Marne Marne LINESTRING (3.254238 48.977...\n#> 19   Seine-Saint-Denis Marne LINESTRING (2.595133 48.876...\n#> 25        Val-de-Marne Marne LINESTRING (2.53346 48.8581...\n#> 30         Haute-Marne Marne LINESTRING (5.407725 47.877...\n#> 5       Seine-Maritime Seine LINESTRING (1.071621 49.309...\n#> 12                Eure Seine LINESTRING (1.514229 49.077...\n#> 14.1             Marne Seine LINESTRING (3.868337 48.522...\n#> 15           Val-Doise Seine LINESTRING (2.286567 48.954...\nfrance_intersected %>%\n  ggplot() + \n  geom_sf(alpha = 0.8, aes(fill = ID, col = ID)) + \n  labs(\n    title = \"Seine, Marne and Yonne rivers\",\n    caption = \"Colours depict French administrative regions\"\n    ) +\n  theme(legend.title = element_blank())\nst_join(france, seine) %>% \n  filter(!is.na(name)) %>% ## Get rid of regions with no overlap\n  distinct(ID, .keep_all = T) %>% ## Some regions are duplicated b/c two branches of the river network flow through them \n  ggplot() + \n  geom_sf(alpha = 0.8, fill = \"black\", col = \"gray50\") + \n  geom_sf(data = seine, col = \"#05E9FF\", lwd = 1) + \n  labs(title = \"Intersected regions only\") "},{"path":"spatial-analysis.html","id":"aside-sf-and-data.table","chapter":"5 Spatial analysis","heading":"5.3.6 Aside: sf and data.table","text":"sf objects designed integrate tidyverse workflow. can also made work data.table workflow , integration slick. known issue ’ll just highlight brief considerations.can convert sf object data.table. note key geometry column appears lose attributes.good news information still . ’s just hidden display.’s upshot? Well, basically means refer “geometry” column explicitly whenever implement spatial operation. example, ’s repeat st_union() operation saw earlier. Note explicitly refer “geometry” column st_union() operation (, moreover, takes place \n“j” data.table slot) assigning aesthetics ggplot() call.course, ’s also possible efficiently convert two classes — e.g. .data.table() st_as_sf() — depending particular section code (data wrangling spatial operation). find often use approach work.","code":"\n# library(data.table) ## Already loaded\n\nnc_dt = as.data.table(nc)\nhead(nc_dt)\n#>     AREA PERIMETER CNTY_ CNTY_ID        NAME  FIPS FIPSNO CRESS_ID BIR74 SID74\n#> 1: 0.114     1.442  1825    1825        Ashe 37009  37009        5  1091     1\n#> 2: 0.061     1.231  1827    1827   Alleghany 37005  37005        3   487     0\n#> 3: 0.143     1.630  1828    1828       Surry 37171  37171       86  3188     5\n#> 4: 0.070     2.968  1831    1831   Currituck 37053  37053       27   508     1\n#> 5: 0.153     2.206  1832    1832 Northampton 37131  37131       66  1421     9\n#> 6: 0.097     1.670  1833    1833    Hertford 37091  37091       46  1452     7\n#>    NWBIR74 BIR79 SID79 NWBIR79 geometry\n#> 1:      10  1364     0      19  <XY[1]>\n#> 2:      10   542     3      12  <XY[1]>\n#> 3:     208  3616     6     260  <XY[1]>\n#> 4:     123   830     2     145  <XY[3]>\n#> 5:    1066  1606     3    1197  <XY[1]>\n#> 6:     954  1838     5    1237  <XY[1]>\nnc_dt$geometry\n#> Geometry set for 100 features \n#> geometry type:  MULTIPOLYGON\n#> dimension:      XY\n#> bbox:           xmin: -84.32385 ymin: 33.88199 xmax: -75.45698 ymax: 36.58965\n#> geographic CRS: NAD27\n#> First 5 geometries:\n#> MULTIPOLYGON (((-81.47276 36.23436, -81.54084 3...\n#> MULTIPOLYGON (((-81.23989 36.36536, -81.24069 3...\n#> MULTIPOLYGON (((-80.45634 36.24256, -80.47639 3...\n#> MULTIPOLYGON (((-76.00897 36.3196, -76.01735 36...\n#> MULTIPOLYGON (((-77.21767 36.24098, -77.23461 3...\nnc_dt[, .(geometry = st_union(geometry))] %>% ## Explicitly refer to 'geometry' col\n    ggplot(aes(geometry = geometry)) +        ## And here again for the aes()\n    geom_sf(fill=NA, col=\"black\") +\n    labs(title = \"Outline of North Carolina\", \n         subtitle = \"This time brought to you by data.table\") \n#> although coordinates are longitude/latitude, st_union assumes that they are planar"},{"path":"spatial-analysis.html","id":"where-to-get-map-data","chapter":"5 Spatial analysis","heading":"5.4 Where to get map data","text":"first North Carolina examples demonstrate, can easily import external shapefiles, KML files, etc., R. Just use generic sf::st_read() function formats sf package take care rest. However, ’ve also seen France example might even need external shapefile. Indeed, R provides access large number base maps — e.g. countries world, US states counties, etc. — maps, (higher resolution) mapdata spData packages, well whole ecosystem specialized GIS libraries.30 convert maps “sf-friendly” data frame format, can use sf::st_as_sf() function per examples.","code":""},{"path":"spatial-analysis.html","id":"example-1-the-world","chapter":"5 Spatial analysis","heading":"5.4.1 Example 1: The World","text":"usual sf functions transformations can applied. example, can reproject world map onto Lambert Azimuthal Equal Area projection (orientate South Pole) follows.","code":"\n# library(maps) ## Already loaded\n\nworld = st_as_sf(map(\"world\", plot = FALSE, fill = TRUE))\n\nworld_map = \n  ggplot(world) + \n  geom_sf(fill = \"grey80\", col = \"grey40\", lwd = 0.3) +\n  labs(\n    title = \"The world\", \n    subtitle = paste(\"EPSG:\", st_crs(world)$epsg)\n    )\nworld_map\nworld_map +\n  coord_sf(crs = \"+proj=laea +y_0=0 +lon_0=155 +lat_0=-90\") +\n  labs(subtitle = \"Lambert Azimuthal Equal Area projection\")"},{"path":"spatial-analysis.html","id":"several-digressions-on-projection-considerations","chapter":"5 Spatial analysis","heading":"5.4.2 Several digressions on projection considerations","text":"","code":""},{"path":"spatial-analysis.html","id":"winkel-tripel-projection","chapter":"5 Spatial analysis","heading":"5.4.2.1 Winkel tripel projection","text":"’ve already seen, map projections work great “box” sf. One niggling notable exception Winkel tripel projection. preferred global map projection National Geographic requires bit work get play nicely sf ggplot2 (detailed thread). ’s quick example :","code":"\n# library(lwgeom) ## Already loaded\n\nwintr_proj = \"+proj=wintri +datum=WGS84 +no_defs +over\"\n\nworld_wintri = lwgeom::st_transform_proj(world, crs = wintr_proj)\n\n## Don't necessarily need a graticule, but if you do then define it manually:\ngr = \n  st_graticule(lat = c(-89.9,seq(-80,80,20),89.9)) %>%\n  lwgeom::st_transform_proj(crs = wintr_proj)\n\nggplot(world_wintri) + \n  geom_sf(data = gr, color = \"#cccccc\", size = 0.15) + ## Manual graticule\n  geom_sf(fill = \"grey80\", col = \"grey40\", lwd = 0.3) +\n  coord_sf(datum = NA) +\n  theme_ipsum(grid = F) +\n  labs(title = \"The world\", subtitle = \"Winkel tripel projection\")"},{"path":"spatial-analysis.html","id":"equal-earth-projection","chapter":"5 Spatial analysis","heading":"5.4.2.2 Equal Earth projection","text":"latest greatest projection, however, “Equal Earth” projection. work well box, part due ne_countries dataset comes bundled rnaturalearth package (link). ’ll explain second part previous sentence moment. first let’s see Equal Earth projection action.","code":"\n# library(rnaturalearth) ## Already loaded\n\ncountries = \n  ne_countries(returnclass = \"sf\") %>%\n  st_transform(8857) ## Transform to equal earth projection\n  # st_transform(\"+proj=eqearth +wktext\") ## PROJ string alternative\n\nggplot(countries) +\n  geom_sf(fill = \"grey80\", col = \"grey40\", lwd = 0.3) +\n  labs(title = \"The world\", subtitle = \"Equal Earth projection\")"},{"path":"spatial-analysis.html","id":"pacfic-centered-maps-and-other-polygon-mishaps","chapter":"5 Spatial analysis","heading":"5.4.2.3 Pacfic-centered maps and other polygon mishaps","text":"noted, rnaturalearth::ne_countries spatial data frame important correctly displaying Equal Earth projection. face , looks pretty similar maps::world spatial data frame earlier. contain polygons countries world appear similar default projections. However, underlying nuances polygons constructed allows us avoid undesirable visual artefacts arise reprojecting Equal Earth projection. Consider:types visual artefacts particularly common Pacific-centered maps , case, arise polygons extending Greenwich prime meridian. ’s suprisingly finicky problem solve. Even rnaturalearth doesn’t good job. Luckily, Nate Miller covered excellent guide set right track.","code":"\nworld %>%\n  st_transform(8857) %>% ## Transform to equal earth projection\n  ggplot() +\n  geom_sf(fill = \"grey80\", col = \"grey40\", lwd = 0.3) +\n  labs(title = \"The... uh, world\", subtitle = \"Projection fail\")"},{"path":"spatial-analysis.html","id":"example-2-a-single-country-i.e.-norway","chapter":"5 Spatial analysis","heading":"5.4.3 Example 2: A single country (i.e. Norway)","text":"maps mapdata packages detailed county- province-level data several individual nations. ’ve already seen France, includes USA, New Zealand several nations. However, can still use extract specific country’s border using intuitive syntax. example, plot base map Norway follows.Hmmm. Looks okay, don’t really want include non-mainland territories like Svalbaard (north) Faroe Islands (east). gives chance show another handy function, sf::st_crop(), ’ll use crop sf object specific extent (.e. rectangle). , also improve projection. Norwegian Mapping Authority recommends ETRS89 / UTM projection, can easily obtain equivalent EPSG code (.e. 25832) website.go. nice-looking map Norway. Fairly appropriate resembles gnarly black metal guitar.Aside: recommend detaching maps package ’re finished using , since avoids potential namespace conflicts purrr::map.","code":"\nnorway = st_as_sf(map(\"world\", \"norway\", plot = FALSE, fill = TRUE))\n\n## For a hi-resolution map (if you *really* want to see all the fjords):\n# norway = st_as_sf(map(\"worldHires\", \"norway\", plot = FALSE, fill = TRUE))\n\nnorway %>%\n  ggplot() + \n  geom_sf(fill=\"black\", col=NA)\nnorway %>%\n  st_crop(c(xmin=0, xmax=35, ymin=0, ymax=72)) %>%\n  st_transform(crs = 25832) %>%\n  ggplot() + \n  geom_sf(fill=\"black\", col=NA)\ndetach(package:maps) ## To avoid potential purrr::map() conflicts"},{"path":"spatial-analysis.html","id":"census","chapter":"5 Spatial analysis","heading":"5.5 BONUS 1: US Census data with tidycensus and tigris","text":"Note: continuing section, first need request API key Census.Working Census data traditionally quite pain. need register website, download data various years geographies separately, merge individual files, etc. Thankfully, recently become much easier thanks Census API — R least — tidycensus (link) tigris (link) packages Kyle Walker (UO alum). next section closely follow tutorial website.start loading packages setting Census API key. Note ’m actually running chunk, since expect fill Census key. run function .Let’s say goal provide snapshot Census rental estimates across different cities Pacific Northwest. start downloading tract-level rental data Oregon Washington using tidycensus::get_acs() function. Note ’ll need look correct ID variable (case: “DP04_0134”).returns sf object, can plot directly.Hmmm, looks like want avoid renting Seattle possible…map provides rental information pretty much Pacific Northwest. Perhaps ’re interested broad swatch geography. ’d rather get sense rents within smaller well-defined metropolitan areas? Well, ’d need detailed geographic data starters, say TIGER/Line shapefiles collection. good news tigris package covered . example, let’s say want narrow focus compare rents across three Oregon metros: Portland (surrounds), Corvallis, Eugene.Now spatial join two data sets using sf::st_join() function.One useful way summarize data compare across metros histogram. Note “regular” ggplot2 geoms functions play perfectly nicely sf objects (.e. aren’t limited geom_sf()).’s quick taste working tidycensus (tigris). truth, package can lot ’ve shown . example, can also use download variety Census microdata PUMS, much detailed. See tidycensus website information.","code":"\n# library(tidycensus) ## Already loaded\n# library(tigris) ## Already loaded\n\n## Replace the below with your own census API key. We'll use the \"install = TRUE\"\n## option to save the key for future use, so we only ever have to run this once.\ncensus_api_key(\"YOUR_CENSUS_API_KEY_HERE\", install = TRUE)\n\n## Also tell the tigris package to automatically cache its results to save on\n## repeated downloading. I recommend adding this line to your ~/.Rprofile file\n## so that caching is automatically enabled for future sessions. A quick way to\n## do that is with the `usethis::edit_r_profile()` function.\noptions(tigris_use_cache=TRUE)\nrent = \n  tidycensus::get_acs(\n    geography = \"tract\", variables = \"DP04_0134\",\n    state = c(\"WA\", \"OR\"), geometry = TRUE\n    )\nrent#> Simple feature collection with 2292 features and 5 fields (with 10 geometries empty)\n#> geometry type:  MULTIPOLYGON\n#> dimension:      XY\n#> bbox:           xmin: -124.7631 ymin: 41.99179 xmax: -116.4635 ymax: 49.00249\n#> geographic CRS: NAD83\n#> # A tibble: 2,292 x 6\n#>    GEOID  NAME         variable estimate   moe                          geometry\n#>    <chr>  <chr>        <chr>       <dbl> <dbl>                <MULTIPOLYGON [°]>\n#>  1 53061… Census Trac… DP04_01…     1181   168 (((-122.2311 48.00875, -122.2288…\n#>  2 53033… Census Trac… DP04_01…     1208    97 (((-122.3551 47.52103, -122.3551…\n#>  3 53077… Census Trac… DP04_01…      845   208 (((-120.9789 46.66908, -120.9792…\n#>  4 53033… Census Trac… DP04_01…     1727   112 (((-122.3555 47.65542, -122.3555…\n#>  5 53027… Census Trac… DP04_01…      727   147 (((-123.7275 47.07135, -123.7264…\n#>  6 53061… Census Trac… DP04_01…     2065   331 (((-122.1409 48.06446, -122.1402…\n#>  7 53033… Census Trac… DP04_01…     1333   142 (((-122.3551 47.50711, -122.3551…\n#>  8 53077… Census Trac… DP04_01…     1290   155 (((-120.5724 46.59989, -120.5619…\n#>  9 53011… Census Trac… DP04_01…     1272    62 (((-122.5589 45.62102, -122.5548…\n#> 10 53021… Census Trac… DP04_01…      550   189 (((-119.0936 46.28581, -119.0934…\n#> # … with 2,282 more rows\nrent %>%\n  ggplot() + \n  geom_sf(aes(fill = estimate, color = estimate)) + \n  coord_sf(crs = 26910) + \n  scale_fill_viridis_c(name = \"Rent ($)\", labels = scales::comma) + \n  scale_color_viridis_c(name = \"Rent ($)\", labels = scales::comma) +\n  labs(\n    title = \"Rental rates across Oregon and Washington\", \n    caption = \"Data: US Census Bureau\"\n    ) \nor_metros = \n  tigris::core_based_statistical_areas(cb = TRUE) %>%\n  # filter(GEOID %in% c(\"21660\", \"18700\", \"38900\")) %>% ## Could use GEOIDs directly if you know them \n  filter(grepl(\"Portland|Corvallis|Eugene\", NAME)) %>%\n  filter(grepl(\"OR\", NAME)) %>% ## Filter out Portland, ME\n  select(metro_name = NAME)\nor_rent = \n  st_join(\n    rent, \n    or_metros, \n    join = st_within, left = FALSE\n    ) \nor_rent\n#> Simple feature collection with 595 features and 6 fields\n#> geometry type:  MULTIPOLYGON\n#> dimension:      XY\n#> bbox:           xmin: -124.1587 ymin: 43.43739 xmax: -121.5144 ymax: 46.38863\n#> geographic CRS: NAD83\n#> # A tibble: 595 x 7\n#>    GEOID  NAME   variable estimate   moe                    geometry metro_name \n#>  * <chr>  <chr>  <chr>       <dbl> <dbl>          <MULTIPOLYGON [°]> <chr>      \n#>  1 53011… Censu… DP04_01…     1272    62 (((-122.5589 45.62102, -12… Portland-V…\n#>  2 53011… Censu… DP04_01…     1185   112 (((-122.5528 45.69343, -12… Portland-V…\n#>  3 53011… Censu… DP04_01…      866    64 (((-122.6143 45.63259, -12… Portland-V…\n#>  4 53011… Censu… DP04_01…     1268    62 (((-122.5282 45.60814, -12… Portland-V…\n#>  5 53011… Censu… DP04_01…     1268   267 (((-122.6002 45.78026, -12… Portland-V…\n#>  6 53011… Censu… DP04_01…     1274   107 (((-122.5603 45.66535, -12… Portland-V…\n#>  7 53011… Censu… DP04_01…     1092    77 (((-122.3562 45.57666, -12… Portland-V…\n#>  8 53011… Censu… DP04_01…     1427   106 (((-122.6576 45.69122, -12… Portland-V…\n#>  9 53011… Censu… DP04_01…     1148   132 (((-122.667 45.6664, -122.… Portland-V…\n#> 10 53011… Censu… DP04_01…     1074    76 (((-122.6716 45.62722, -12… Portland-V…\n#> # … with 585 more rows\nor_rent %>%\n  ggplot(aes(x = estimate)) + \n  geom_histogram() + \n  facet_wrap(~metro_name) "},{"path":"spatial-analysis.html","id":"bonus-2-interactive-maps","chapter":"5 Spatial analysis","heading":"5.6 BONUS 2: Interactive maps","text":"Now ’ve grasped basic properties sf objects plot using ggplot2, time scale interactive maps.31 several package options . think best leaflet (link) friends, plotly (link). ’ve already covered latter previous lecture, ’ll simply redirect interested parties link map-related examples examples. expand former depth, leaflet.js lightweight JavaScript library interactive mapping become extremely popular recent years. seen used across major news media publications (New York Times, Washington Post, Economist, etc.). good people RStudio kindly packaged version leaflet R, basically acts wrapper underlying JavaScript library.leaflet syntax little different ’ve seen thus far strongly encourage visit package’s excellent website full set options. However, key basic principle shares ggplot2 build plot layers. ’s example adapted Julia Silge, builds tidycensus package saw . time, goal plot county-level population densities Oregon whole produce helpful popup text user clicks particular county. First, download data using tidycensus inspect resulting data frame., popup text interest held within “NAME” “estimate” columns. ’ll use bit regular expression work extract county name “NAME” column (.e. without state) build map layer layer. Note leaflet syntax requires prepend variables names tilde (~) refer plot building process. tilde operates much way asthetics (aes()) function ggplot2. One thing note need define colour palette — ’ll call col_pal — separately main plot. bit inconvenience ’re used fully-integrated ggplot2 API, small one.suprises . bulk Oregon’s population situated just west Cascades, cities connected along -5.particularly useful feature interactive maps limited scale granularity, can really dig specific areas neighbourhoods. ’s example using home values Lane County.tried convince conceptual similarities building maps either leaflet ggplot2 — layering etc. — ’s denying syntax take getting used . plan spin occasional interactive map, cognitive overhead might effort ’s worth. good news R spatial community created mapview package (link) quickly generating interactive maps. Behind scenes, uses leaflet power everything, alongside sensible defaults. ’s quick example recreates Lane county home value map .Super easy, ? doesn’t offer quite flexibility native leaflet syntax, mapview great way get decent interactive maps running minimal effort.32","code":"\n# library(tidycensus) ## Already loaded\n\noregon = \n  get_acs(\n    geography = \"county\", variables = \"B01003_001\",\n    state = \"OR\", geometry = TRUE\n    ) \noregon#> Simple feature collection with 36 features and 5 fields\n#> geometry type:  MULTIPOLYGON\n#> dimension:      XY\n#> bbox:           xmin: -124.5662 ymin: 41.99179 xmax: -116.4635 ymax: 46.29204\n#> geographic CRS: NAD83\n#> First 10 features:\n#>    GEOID                     NAME   variable estimate moe\n#> 1  41017 Deschutes County, Oregon B01003_001   186251  NA\n#> 2  41003    Benton County, Oregon B01003_001    91107  NA\n#> 3  41015     Curry County, Oregon B01003_001    22650  NA\n#> 4  41061     Union County, Oregon B01003_001    26337  NA\n#> 5  41055   Sherman County, Oregon B01003_001     1642 114\n#> 6  41051 Multnomah County, Oregon B01003_001   804606  NA\n#> 7  41007   Clatsop County, Oregon B01003_001    39102  NA\n#> 8  41033 Josephine County, Oregon B01003_001    86251  NA\n#> 9  41031 Jefferson County, Oregon B01003_001    23607  NA\n#> 10 41039      Lane County, Oregon B01003_001   373340  NA\n#>                          geometry\n#> 1  MULTIPOLYGON (((-122.0019 4...\n#> 2  MULTIPOLYGON (((-123.8167 4...\n#> 3  MULTIPOLYGON (((-124.3239 4...\n#> 4  MULTIPOLYGON (((-118.6978 4...\n#> 5  MULTIPOLYGON (((-121.0312 4...\n#> 6  MULTIPOLYGON (((-122.9292 4...\n#> 7  MULTIPOLYGON (((-123.5989 4...\n#> 8  MULTIPOLYGON (((-124.042 42...\n#> 9  MULTIPOLYGON (((-121.8495 4...\n#> 10 MULTIPOLYGON (((-124.1503 4...\n# library(leaflet) ## Already loaded\n\ncol_pal = colorQuantile(palette = \"viridis\", domain = oregon$estimate, n = 10)\n\noregon %>%\n  mutate(county = gsub(\",.*\", \"\", NAME)) %>% ## Get rid of everything after the first comma\n  st_transform(crs = 4326) %>%\n  leaflet(width = \"100%\") %>%\n  addProviderTiles(provider = \"CartoDB.Positron\") %>%\n  addPolygons(\n    popup = ~paste0(county, \"<br>\", \"Population: \", prettyNum(estimate, big.mark=\",\")),\n    stroke = FALSE,\n    smoothFactor = 0,\n    fillOpacity = 0.7,\n    color = ~col_pal(estimate)\n    ) %>%\n  addLegend(\n    \"bottomright\", \n    pal = col_pal, \n    values = ~estimate,\n    title = \"Population percentiles\",\n    opacity = 1\n    )\nlane = \n  get_acs(\n    geography = \"tract\", variables = \"B25077_001\", \n    state = \"OR\", county = \"Lane County\", geometry = TRUE\n    )\n#> Getting data from the 2015-2019 5-year ACS\n#> Downloading feature geometry from the Census website.  To cache shapefiles for use in future sessions, set `options(tigris_use_cache = TRUE)`.\nlane_pal = colorNumeric(palette = \"plasma\", domain = lane$estimate)\n\nlane %>%\n  mutate(tract = gsub(\",.*\", \"\", NAME)) %>% ## Get rid of everything after the first comma\n  st_transform(crs = 4326) %>%\n  leaflet(width = \"100%\") %>%\n  addProviderTiles(provider = \"CartoDB.Positron\") %>%\n  addPolygons(\n    # popup = ~tract,\n    popup = ~paste0(tract, \"<br>\", \"Median value: $\", prettyNum(estimate, big.mark=\",\")),\n    stroke = FALSE,\n    smoothFactor = 0,\n    fillOpacity = 0.5,\n    color = ~lane_pal(estimate)\n    ) %>%\n  addLegend(\n    \"bottomright\", \n    pal = lane_pal, \n    values = ~estimate,\n    title = \"Median home values<br>Lane County, OR\",\n    labFormat = labelFormat(prefix = \"$\"),\n    opacity = 1\n    )\n# library(mapview) ## Already loaded\n\nmapview::mapview(lane, zcol = \"estimate\", \n                 layer.name = 'Median home values<br>Lane County, OR')"},{"path":"spatial-analysis.html","id":"bonus-3-other-map-plotting-options-plot-tmap-etc.","chapter":"5 Spatial analysis","heading":"5.7 BONUS 3: Other map plotting options (plot, tmap, etc.)","text":"think ggplot2 (together sf) leaflet best value bet map plotting R — especially relative newcomers inculcated tidyverse ecosystem — said many options available . base R plot() function powerful handles manner spatial objects. (also fast.) package ’ll highlight briefly closing, however, tmap (link). focus tmap thematic maps “production ready.” package extremely flexible can accept various spatial objects output various map types (including interactive). Moreover, syntax look familar us, since inspired ggplot2’s layered graphics grammar approach. ’s example great looking map taken tmap homepage.","code":"\n# library(tmap) ## Already loaded\n# library(tmaptools) ## Already loaded\n\n## Load elevation raster data, and country polygons\ndata(land, World)\n\n## Convert to Eckert IV projection\nland_eck4 = st_transform(land, \"+proj=eck4\")\n\n## Plot\ntm_shape(land_eck4) +\n  tm_raster(\n    \"elevation\", \n    breaks=c(-Inf, 250, 500, 1000, 1500, 2000, 2500, 3000, 4000, Inf),  \n    palette = terrain.colors(9), \n    title=\"Elevation\"\n    ) +\n  tm_shape(World) +\n  tm_borders(\"grey20\") +\n  tm_graticules(labels.size = .5) +\n  tm_text(\"name\", size=\"AREA\") +\n  tm_compass(position = c(.65, .15), color.light = \"grey90\") +\n  tm_credits(\"Eckert IV projection\", position = c(\"RIGHT\", \"BOTTOM\")) +\n  tm_style(\"classic\") +\n  tm_layout(\n    inner.margins=c(.04,.03, .02, .01),\n    legend.position = c(\"left\", \"bottom\"),\n    legend.frame = TRUE,\n    bg.color=\"lightblue\",\n    legend.bg.color=\"lightblue\",\n    earth.boundary = TRUE,\n    space.color=\"grey90\"\n    ) "},{"path":"spatial-analysis.html","id":"further-reading","chapter":"5 Spatial analysis","heading":"5.8 Further reading","text":"easily spend whole semester (degree!) spatial analysis , broadly, geocomputation. ’ve simply tried give much useful information can reasonably contained one lecture. resources reading study:package websites ’ve linked throughout tutorial obvious next port call delving deeper functionality: sf, leaflet, etc.best overall resource right now may Geocomputation R, superb new text Robin Lovelace, Jakub Nowosad, Jannes Muenchow. “living,” open-source document, constantly updated authors features modern approach working geographic data. Highly recommended.Similarly, rockstar team behind sf, Edzer Pebesma Roger Bivand, busy writing book, Spatial Data Science. project currently less developed, expect become key reference point years come. Imporantly, books cover raster-based spatial data.subject raster data… ’re market shorter guides, Jamie Montgomery great introduction rasters . advanced level, sf team busy developing new package called stars, provide equivalent functionality (among things) raster data. UPDATE: ended caving wrote short set bonus notes rasters .want advice drawing maps, including bunch didn’t cover today (choropleths, state-bins, etc.), Kieran Healy’s Data Vizualisation book covered.Something else didn’t really cover today spatial statistics. subject degree-length treatment. However, now ’ll simply point Spatio-Temporal Statistics R, Christopher Wikle coauthors. (Another free book!) Finally, since likely interesting thing economists working spatial data, ’ll also add Darin Christensen Thiemo Fetzer written fast R-implementation (via C++) Conley standard errors. GitHub repo . See original blog post (update) details.","code":""},{"path":"gce-i.html","id":"gce-i","chapter":"6 Google Compute Engine (I)","heading":"6 Google Compute Engine (I)","text":"first two chapters Google Compute Engine. ’ll learn run R RStudio Server virtual machines (VMs) cloud. means ’ll able conduct analysis (almost) exactly user environment ’re used , now full power cloud-based computation disposal. Trust , awesome.","code":""},{"path":"gce-i.html","id":"requirements-1","chapter":"6 Google Compute Engine (I)","heading":"6.1 Requirements","text":"","code":""},{"path":"gce-i.html","id":"create-an-account-on-google-cloud-platform-free","chapter":"6 Google Compute Engine (I)","heading":"6.1.1 Create an account on Google Cloud Platform (free)","text":"next instructions important, please read carefully.Sign 12-month ($300 credit) free trial Google Cloud Platform (GCP). requires existing Google/Gmail account.33 course sign-, ’ll prompted enter credit card details billing purposes. Don’t worry, won’t charged unless/actively request continued access GCP free trial ends. billable project ID required gaining access platform.Download follow installation instructions Google Cloud SDK command line utility, gcloud. ’ll connect GCP local computers via shell.","code":""},{"path":"gce-i.html","id":"introduction","chapter":"6 Google Compute Engine (I)","heading":"6.2 Introduction","text":"","code":""},{"path":"gce-i.html","id":"to-the-cloud","chapter":"6 Google Compute Engine (I)","heading":"6.2.1 To the cloud!","text":"Thus far course, ’ve spent quite lot time learning code efficiently. ’ve covered topics like functional programming, caching, parallel programming, . tools help make computational resources disposal. However, ’s limit far can take . point, datasets become big, simulations become complex, regressions take damn long run run laptop. solution beyond point bigger boat power.easiest cheapest way access computational power days cloud.34 number excellent cloud service providers, ’m going focus Google Cloud Platform (GCP).35 GCP offers range incredibly useful services — ’ll cover later lectures — 12-month free trial makes ideal entry point learning cloud computation.particular GCP product ’re going use today Google Compute Engine (GCE). GCE service allows users launch -called virtual machines demand cloud (.e. Google’s data centers). ’s lot can say — say later — benefits can bring us. right now, may well asking : “virtual machine need one anyway?”, let’s take step back quickly clear terminology.","code":""},{"path":"gce-i.html","id":"virtual-machines-vms","chapter":"6 Google Compute Engine (I)","heading":"6.2.2 Virtual machines (VMs)","text":"virtual machine (VM) just emulation computer running inside another (bigger) computer. can potentially perform operations physical laptop desktop . might even share many properties, operating system internal architecture. key advantage VM perspective powerful machines can “spun ” cloud almost effortlessly deployed tackle jobs beyond capabilities local computer. Got big dataset requires much memory analyse old laptop? Load high-powered VM. Got code takes age run? Fire VM let chug away without consuming local resources. , better yet, write code runs parallel spin VM lots cores get analysis done fraction time. need working internet connection web browser.Now, background knowledge mind, GCE delivers high-performance, rapidly scalable VMs. new VM can deployed shut within seconds, existing VMs can easily ramped depending project’s needs (cores added, RAM added, etc.) experience, people hard-pressed spent couple dollars month using GCE free trial . especially true researchers data scientists need fire VM, VM cluster, occasionally computationally-intensive part project, can easily switch used.Disclaimer: much stand paragraph, ultimately responsibility keep track billing utilisation rates. Take look GCP’s Pricing Calculator see much can expect charged particular machine level usage. can even set budget create usage alerts want extra cautious.","code":""},{"path":"gce-i.html","id":"roadmap","chapter":"6 Google Compute Engine (I)","heading":"6.2.3 Roadmap","text":"goal next two lectures set VM (cluster VMs) GCE. ’s , want install R RStudio (Server) VMs, can interact exactly way ’re used computers. ’m going show two approaches:Manually configure GCE RStudio Server (today)Automate googleComputeEngineR friends (next lecture)approaches merits, think ’s important start manual configuration get good understanding ’s happening underneath hood. Let’s get started.","code":""},{"path":"gce-i.html","id":"install-r-and-rstudio-server-on-gce","chapter":"6 Google Compute Engine (I)","heading":"6.3 Install R and RStudio Server on GCE","text":"Note: ’s possible complete nearly steps section via GCE browser console. However, ’ll stick using shell, make easier document steps.Windows users: need run multi-line commands (.e. chained backslash character) single line commands. Basically, delete trailing “\\” characters end sub-lines run one long command single line.","code":""},{"path":"gce-i.html","id":"confirm-that-you-have-installed-gcloud-correctly","chapter":"6 Google Compute Engine (I)","heading":"6.3.1 Confirm that you have installed gcloud correctly","text":"’ll need choose operating system (OS) VM, well designated zone. Let’s quickly look available options, since also good time confirm correctly installed gcloud command-line interface. Open shell enter:Tip: get error message commands, try re-running sudo beginning. works , need append “sudo” shell commands lecture.’ll know everything working properly commands return large range options. get error, please try reinstalling gcloud continuing.","code":"## user@localhost:~$\n\ngcloud compute images list\ngcloud compute zones list"},{"path":"gce-i.html","id":"create-a-vm","chapter":"6 Google Compute Engine (I)","heading":"6.3.2 Create a VM","text":"key shell command creating VM gcloud compute instances create.\ncan specify type machine want range options using appropriate flags. Let first show example command walk (somewhat arbitrary) choices detail. Note going call VM instance “-vm,” can call whatever want.Tip: Windows users, remember can’t execute multi-line shell commands. Delete trailing “\\” characters run one long command single line.breakdown command quick explanation choices.gcloud compute instances create -vm: Create new VM called “-vm.” Yes, creative.--image-family ubuntu-2004-lts --image-project ubuntu-os-cloud: Use Ubuntu 20.04 underlying operating system.--machine-type n1-standard-8: ’ve elected go “N1 Standard 8” option, means ’m getting 8 CPUs 30GB RAM. However, can choose range machine/memory/pricing options. (Assuming monthly usage rate 20 hours, particular VM cost $7.60 month maintain free trial ends.) needn’t worry much initial specs now. New VMs easy create discard get hang . ’s also simple change specs already-created VM. GCE even suggest cheaper specifications thinks aren’t using resources efficiently line.--zone us-west1-: preferred zone. zone choice shouldn’t really matter, although ’ll prompted choose one forget include flag. general rule, advise picking whatever’s closest .36Assuming ran command (perhaps changing zone one nearest ), see something like following:Write External IP address, ’ll need running RStudio Server later.37","code":"## user@localhost:~$\n\ngcloud compute instances create my-vm \\\n  --image-family ubuntu-2004-lts --image-project ubuntu-os-cloud \\\n  --machine-type n1-standard-8 \\\n  --zone us-west1-aCreated [https://www.googleapis.com/compute/v1/projects/YOUR-PROJECT/zones/YOUR-ZONE/instances/YOUR-VM].\nNAME   ZONE        MACHINE_TYPE   PREEMPTIBLE  INTERNAL_IP    EXTERNAL_IP   STATUS\nmy-vm  us-west1-a  n1-standard-8               10.138.15.222  34.105.81.92  RUNNING"},{"path":"gce-i.html","id":"allow-rstudios-8787-port-via-a-firewall-rule-only-once","chapter":"6 Google Compute Engine (I)","heading":"6.3.2.1 Allow RStudio’s 8787 port via a firewall rule (only once)","text":"RStudio Server runs port 8787 associated IP address. Google Cloud default blocks external traffic GCE VMs security reasons, first need enable 8787 port via firewall rule. following command creates firewall rule (’m calling “rstudio”) exactly .Note firewall rules across every VM project. run command .38","code":"## user@localhost:~$\n\ngcloud compute firewall-rules create rstudio --allow=tcp:8787"},{"path":"gce-i.html","id":"logging-in","chapter":"6 Google Compute Engine (I)","heading":"6.3.3 Logging in","text":"Congratulations: Set-GCE VM instance already complete.(Easy, wasn’t ?)next step log via SSH (.e. Secure Shell). simple matter providing VM’s name zone. forget specify zone haven’t assigned default, ’ll prompted.IMPORTANT: Upon logging GCE instance via SSH first time, prompted generate key passphrase. Needless say, make note passphrase future long-ins. passphrase required future remote log-ins Google Cloud projects via gcloud SSH local computer. includes additional VMs create project account.Passphrase successfully created entered, now connected VM via SSH. , see something like following, “grant” “-vm” obviously replaced username VM hostname.Next, ’ll install R VM.","code":"## user@localhost:~$\n\ngcloud compute ssh my-vm --zone us-west1-agrant@my-vm:~$"},{"path":"gce-i.html","id":"install-r","chapter":"6 Google Compute Engine (I)","heading":"6.3.4 Install R","text":"can find full set instructions recommendations installing R Ubuntu . can just follow choices , cover everything need. Note running commands directly shell connected VM.Aside: apt commands referring Aptitude package management system. Think like Homebrew Ubuntu (Debian-based Linux distributions).Base R now installed ready go VM. However, ’m going walk two extra steps, since avoid common headaches road.First, ’re going change get R libraries :command sets default library source RStudio Package Manager (RSPM), instead usual CRAN mirror(s). ? Well, RSPM provides precompiled R package binaries Linux, whereas CRAN requires us install build source. don’t want worry much .39 Just trust command allow us install R packages much faster fewer hiccups.Second, let’s install additional system libraries VM:system libraries needed power common R packages hood. example, ’ve just installed underlying geospatial libraries support sf package.","code":"## grant@my-vm:~$\n\nsudo sh -c 'echo \"deb https://cloud.r-project.org/bin/linux/ubuntu focal-cran40/\" >> \\\n  /etc/apt/sources.list'\nsudo apt-key adv --keyserver keyserver.ubuntu.com \\\n  --recv-keys E298A3A825C0D65DFD57CBB651716619E084DAB9\nsudo apt update && sudo apt upgrade -y\nsudo apt install -y r-base r-base-dev## grant@my-vm:~$\n\nsudo sh -c 'echo \"options(repos = c(RSPM = \\\"https://packagemanager.rstudio.com/all/__linux__/focal/latest\\\"))\" \\\n  >> `R RHOME`/etc/Rprofile.site'## grant@my-vm:~$ \n\nsudo apt install -y libudunits2-dev libgdal-dev gdal-bin libgeos-dev libproj-dev \\\n  libcairo2-dev"},{"path":"gce-i.html","id":"install-and-configure-rstudio-server","chapter":"6 Google Compute Engine (I)","heading":"6.3.5 Install and configure RStudio Server","text":"followed steps , already launch directly R shell.40 However, ’d obviously prefer use awesome IDE interface provided RStudio (Server). ’s ’ll install configure next, making sure can run RStudio Server VM via web browser local computer.","code":""},{"path":"gce-i.html","id":"download-rstudio-server-on-your-vm","chapter":"6 Google Compute Engine (I)","heading":"6.3.5.1 Download RStudio Server on your VM","text":"check latest available version Rstudio Server . time writing, following need:","code":"## grant@my-vm:~$\n\nsudo apt install gdebi-core\nwget https://download2.rstudio.org/server/bionic/amd64/rstudio-server-1.4.1106-amd64.deb\nsudo gdebi rstudio-server-1.4.1106-amd64.deb ## Hit \"y\" when prompted"},{"path":"gce-i.html","id":"add-a-user","chapter":"6 Google Compute Engine (I)","heading":"6.3.5.2 Add a user","text":"Now ’re connected VM, might notice never actually logged specific user. (discussion .) doesn’t matter applications, RStudio Server specifically requires username/password combination. must first create new user give password continuing. example, can create new user called “elvis” like :prompted specify user password (confirm various bits biographical information can ignore). optional, recommended step add new user sudo group. ’ll cover depth later tutorial, part sudo group allow Elvis temporarily invoke superuser priviledges needed.Tip: created, can now log user’s account VM directly via SSH, e.g. gcloud compute ssh elvis@-vm --zone us-west1-","code":"## grant@my-vm:~$\n\nsudo adduser elvis## grant@my-v m:~$ \n\nsudo usermod -aG sudo elvis\n# grant@my-vm:~$ su - elvis ## Log in as elvis on SSH (optional)"},{"path":"gce-i.html","id":"navigate-to-the-rstudio-server-instance-in-your-browser","chapter":"6 Google Compute Engine (I)","heading":"6.3.5.3 Navigate to the RStudio Server instance in your browser","text":"now ready open RStudio Server navigating default 8787 port VM’s External IP address. (remember writing earlier, right?) forgot write IP address , don’t worry: can find logging Google Cloud console looking VM instances, opening new shell window (one currently connected VM) typing:Either way, address, open preferred web browser navigate :http://EXTERNAL-IP-ADDRESS:8787You presented following web page. Log using username/password created earlier.’re set. RStudio Server running laptop via Google Chrome.Tip: Hit F11 go full screen browser. server version RStudio virtually indistinguishable desktop version.","code":"## user@localhost:~$\n\ngcloud compute instances describe my-vm | grep 'natIP'"},{"path":"gce-i.html","id":"stopping-and-restarting-your-vm-instance","chapter":"6 Google Compute Engine (I)","heading":"6.3.6 Stopping and (re)starting your VM instance","text":"Stopping (re)starting VM instance highly advisable, since don’t want get billed times aren’t using . new shell window (one currently synced VM instance):","code":"## user@localhost:~$\n\ngcloud compute instances stop my-vm\ngcloud compute instances start my-vm"},{"path":"gce-i.html","id":"summary","chapter":"6 Google Compute Engine (I)","heading":"6.3.7 Summary","text":"Contratulations! now fully-integrated VM running R RStudio whenever need . Assuming gone initial setup, ’s tl;dr summary deploy existing VM RStudio Server:Start VM instance.Take note External IP address step 3 .Open web browser navigate RStudio Server VM. Enter username password needed. http://EXTERNAL-IP-ADDRESS:8787Open web browser navigate RStudio Server VM. Enter username password needed. http://EXTERNAL-IP-ADDRESS:8787Log-via SSH. (Optional)Log-via SSH. (Optional)Stop VM., remember, really want avoid command line, can always go GCE browser console.","code":"gcloud compute instances start YOUR-VM-INSTANCE-NAMEgcloud compute instances describe YOUR-VM-INSTANCE-NAME | grep 'natIP'gcloud compute ssh YOUR-VM-INSTANCE-NAMEgcloud compute instances stop YOUR-VM-INSTANCE-NAME"},{"path":"gce-i.html","id":"getting-the-most-out-of-r-on-your-gce-setup","chapter":"6 Google Compute Engine (I)","heading":"6.4 Getting the most out of R on your GCE setup","text":"already completed steps ’ll need high-performance computing cloud. VM create GCE using methods ready go RStudio Server whenever want . However, still tweaks tips can use really improve user experience reduce complications interacting VMs local computers. rest tutorial covers main tips recommendations.","code":""},{"path":"gce-i.html","id":"keep-your-system-up-to-date","chapter":"6 Google Compute Engine (I)","heading":"6.4.1 Keep your system up to date","text":"First things first: Remember keep VM date, just like normal computer. recommend run following command (really: two commands) regularly:can also update gcloud utility components local computer (.e. VM) following command:","code":"## grant@my-vm:~$\n\nsudo apt update && sudo apt upgrade## user@localhost:~\n\ngcloud components update"},{"path":"gce-i.html","id":"transfer-and-sync-files-between-your-vm-and-your-local-computer","chapter":"6 Google Compute Engine (I)","heading":"6.4.2 Transfer and sync files between your VM and your local computer","text":"three main options.","code":""},{"path":"gce-i.html","id":"manually-transfer-files-directly-from-rstudio-server","chapter":"6 Google Compute Engine (I)","heading":"6.4.2.1 1. Manually transfer files directly from RStudio Server","text":"RStudio’s “Files” pane (bottom-right) provides various options moving files directories around. includes uploading local computer VM, exporting way around — see screenshot . arguably simplest option works especially well quick small jobs.","code":""},{"path":"gce-i.html","id":"manually-transfer-files-and-folders-using-the-command-line-or-scp","chapter":"6 Google Compute Engine (I)","heading":"6.4.2.2 2. Manually transfer files and folders using the command line or SCP","text":"Manually transferring files folders across systems done fairly easily using command line. Note next code chunk run new shell instance (.e. one connected VM via SSH).’s also possible transfer files using regular desktop file browser thanks SCP. (Linux Mac OSX least. Windows users first need install program call WinSCP.) See .Tip: file browser-based SCP solution much efficient assigned static IP address VM instance — otherwise set time restart VM instance assigned new ephemeral IP address — ’d advise first.","code":"## user@localhost:~\n\ngcloud compute scp \\\n  my-vm:/home/elvis/amazingresults.csv \\\n  ~/locdir/amazingresults-copy.csv \\\n  --zone us-west1-a"},{"path":"gce-i.html","id":"sync-with-github-or-other-cloud-service","chapter":"6 Google Compute Engine (I)","heading":"6.4.2.3 3. Sync with GitHub or other cloud service","text":"preferred option. Ubuntu, like virtually Linux distros, comes Git preinstalled. thus able sync results across systems using Git(Hub) usual fashion. tend use command line Git operations (committing, pulling, pushing, etc.) works exactly expected ’ve SSH’d VM. However, Rstudio Server’s built-Git UI also works well comes nice added functionality (highlighted diff. sections forth).haven’t tried , also able install Box, Dropbox Google Drive VM sync across systems way. go route, ’d advise installing programs sub-directories user’s “home” directory. Even may run problems related user permissions. However, just follow instructions linking hypothetical “TeamProject” folder describe (except must obviously point towards relevant Box/Dropbox/GDrive folder location instead) fine.Tip: Remember VM lives server doesn’t usual graphical interface — including installation utilities — normal desktop. ’ll thus need follow command line installation instructions programs. Make sure scroll relevant sections links provided .Last, least, Google encourage data synchronisation GCE VMs using another product within Cloud Platform, .e. Google Storage. especially useful really big data files folders, beyond scope lecture. (’re interested learning , see .)","code":""},{"path":"gce-i.html","id":"further-resources-3","chapter":"6 Google Compute Engine (I)","heading":"6.5 Further resources","text":"next chapter, ’ll build today’s material showing automate lot steps googleComputeEngineR package related tools. meantime, resources might find useful.recommend consulting official GCE documentation ever get stuck. ’s loads useful advice extra tips getting VM setup, including ways integrate system GCP products like Storage, BigQuery, etc.useful links include RStudio Server documentation, Linux Journey guide anyone wants learn Linux (yes, !).","code":""},{"path":"gce-i.html","id":"bonus-material","chapter":"6 Google Compute Engine (I)","heading":"6.6 Bonus material","text":"","code":""},{"path":"gce-i.html","id":"install-the-intel-math-kernel-library-mkl-or-openblaslapack","chapter":"6 Google Compute Engine (I)","heading":"6.6.1 Install the Intel Math Kernel Library (MKL) or OpenBLAS/LAPACK","text":"discussed previous chapter parallel programming, R ships BLAS/LAPACK libraries default. default works well enough, can get significant speedups switching optimized libraries Intel Math Kernel Library (MKL) OpenBLAS. former slightly faster according benchmark tests ’ve seen, ’s close run thing. Either can installed simple one line command, e.g.Tip: run command shell (SSH), ’ll need consent options. Click TAB keyboard cycle ENTER select. Just say “yes” / “okay” everything.MKL (OpenBLAS) installed, R session automatically configured use default. can check opening R checking sessionInfo() output, return something like:per parallel programming chapter, may also wish switch MKL’s default multithreading capabilities R avoid nested parallelism. can use method saw chapter, set environment variable .Renviron file.","code":"## grant@my-vm:~$ \n\nsudo apt install intel-mklBLAS/LAPACK: /usr/lib/x86_64-linux-gnu/libmkl_rt.soecho \"MKL_NUM_THREADS=1\" >> ~/.Renviron"},{"path":"gce-i.html","id":"share-files-and-libraries-between-multiple-users-on-the-same-vm","chapter":"6 Google Compute Engine (I)","heading":"6.6.2 Share files and libraries between multiple users on the same VM","text":"default configuration described works perfectly well cases single user don’t venture outside home directory (sub directories). Indeed, can just add new folders within user’s home directory using standard Linux commands able access within RStudio Server log user.However, ’s slight wrinkle cases want share information multiple users VM. (may well necessary big group project.) particular, RStudio Server going able look files individual user’s home directory (e.g. /home/elvis.) Similarly, default Linux, R libraries one user installs won’t necessarily available users.reason user permissions; since Elvis automatic “superuser,” RStudio Server doesn’t know allowed access users’ files packages VM, vice versa. Thankfully, ’s fairly easy workaround, involving standard Linux commands adding user group privileges (see slides shell lecture). ’s example solution cover cases:","code":""},{"path":"gce-i.html","id":"share-files-across-users","chapter":"6 Google Compute Engine (I)","heading":"6.6.2.1 Share files across users","text":"Let’s say Elvis working joint project together colleague called Priscilla. (Although, say colleagues…) decided keep shared analysis new directory called TeamProject, located within Elvis’s home directory. Start creating new shared directory:Presumably, real-life Priscilla already user profile point. let’s quickly create one fictional version.Next, create user group. ’m going call “projectgrp,” wish. group setup useful assign set permissions group, members group automatically receive permissions . mind, add Elvis Priscilla “projectgrp” created:Now can set necessary ownership permissions shared TeamProject directory. First, use chown command assign ownership directory default user (case, “elvis”) “projectgrp” members. Second, use chmod 770 command grant read, write execute access directory. cases, ’ll use -R flag recursively set permissions children directories TeamProject/ .next two commands optional, advised Priscilla going working VM TeamProject directory. First, can change primary group ID “projectgrp,” files creates automatically assigned group:Second, can add symbolic link TeamProject directory Priscilla’s home directory, immediately visible logs RStudio Server. (Making sure switch account running command):","code":"## grant@my-vm:~$ \n\nsudo mkdir /home/elvis/TeamProject## grant@my-vm:~$ \n\nsudo adduser priscilla# grant@my-vm:~$ \n\nsudo groupadd projectgrp\nsudo gpasswd -a elvis projectgrp\nsudo gpasswd -a priscilla projectgrp##grant@my-vm:~$\n\nsudo chown -R elvis:projectgrp /home/elvis/TeamProject\nsudo chmod -R 770 /home/elvis/TeamProject## grant@my-vm:~$\n\nsudo usermod -g projectgrp priscilla## grant@my-vm:~$ \n\nsudo su - priscilla\n\n## priscilla@my-vm:~$ \n\nln -s /home/elvis/TeamProject /home/priscilla/TeamProject\nexit\n\n## grant@my-vm:~$"},{"path":"gce-i.html","id":"share-r-libraries-packages-across-users","chapter":"6 Google Compute Engine (I)","heading":"6.6.2.1.1 Share R libraries (packages) across users","text":"default, R package user installs available .\nNow, sharing R libraries across users less critical able share files. However, ’s still potentially annoying install, say, rstan colleague already installed user account. Luckily, solution closely mimics solution file sharing ’ve just seen : ’re going set default system-wide R library path give users access library via group. convenience ’m just going continue “projectgrp” group created . However, also create new group (say, “rusers”), add individual users , proceed way wanted .first thing change permission system-wide R library (.e. get type R RHOME shell). ’re going assign read, write, execute permissions members group. ’ll use -R flag recursively.’s done, tell R make shared library path default user, adding ~/.Renviron file. example, ’s ’d “elvis.”R packages Elvis installs now immediately available Priscilla vice versa.Tip: ’ve already installed packages local (.e. -user-) library path creating system-wide setup, can just move across ‘mv’ command. Something like following work, ’ll need check appropriate paths : elvis@-vm:~$ sudo mv \"/home/elvis/R/x86_64-pc-linux-gnu-library/3.5/*\" /usr/lib/R/library.","code":"## grant@my-vm:~$\n\nsudo chown elvis:projectgrp -R `R RHOME`\nsudo chmod -R 775 `R RHOME`## grant@my-vm:~$ \n\nsu - elvis\n\n## elvis@my-vm:~$\n\n`R RHOME`/library ## Check library path. Should be /usr/lib/R/library\n\necho 'export PATH=\"R_LIBS_USER=/usr/lib/R/library\"' >> ~/.Renviron"}]
